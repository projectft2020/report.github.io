<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¯é‚¦å­¸ç¿’åœ¨å”ä½œé‡åŒ–ç ”ç©¶ä¸­çš„æ‡‰ç”¨</title>
    <style>
        :root {
            --primary-color: #2563eb;
            --secondary-color: #64748b;
            --bg-color: #f8fafc;
            --text-color: #1e293b;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--bg-color);
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
        }
        h1 { color: var(--primary-color); margin-bottom: 0.5rem; }
        h2 { color: var(--primary-color); margin-top: 2rem; border-bottom: 2px solid var(--secondary-color); padding-bottom: 0.5rem; }
        h3 { color: var(--secondary-color); margin-top: 1.5rem; }
        .meta { color: var(--secondary-color); font-size: 0.9rem; margin-bottom: 2rem; }
        .updated { background: #fef3c7; padding: 0.5rem 1rem; border-radius: 8px; display: inline-block; margin-bottom: 1rem; font-size: 0.85rem; }
        pre { background: #1e293b; color: #f8fafc; padding: 1rem; border-radius: 8px; overflow-x: auto; }
        code { background: #e2e8f0; padding: 0.2rem 0.4rem; border-radius: 4px; }
        pre code { background: none; padding: 0; }
        table { width: 100%; border-collapse: collapse; margin: 1rem 0; }
        th, td { border: 1px solid #e2e8f0; padding: 0.75rem; text-align: left; }
        th { background: var(--primary-color); color: white; }
        .back-link { display: inline-block; margin-bottom: 2rem; color: var(--primary-color); text-decoration: none; }
        .back-link:hover { text-decoration: underline; }
    </style>
</head>
<body>
    <a href="index.html" class="back-link">â† è¿”å›ç ”ç©¶å ±å‘Šåˆ—è¡¨</a>
    <div class="updated">ğŸ“… æ›´æ–°æ™‚é–“ï¼š2026-02-21 04:04:16</div>
    <div class="content">
<h1>è¯é‚¦å­¸ç¿’åœ¨é‡åŒ–ç ”ç©¶ä¸­çš„æ‡‰ç”¨ç ”ç©¶</h1>

<strong>Task ID:</strong> f001
<strong>Agent:</strong> Charlie Analyst (Subagent)
<strong>Status:</strong> completed
<strong>Timestamp:</strong> 2026-02-20T18:46:00+08:00

<h2>Executive Summary</h2>

<p>è¯é‚¦å­¸ç¿’ï¼ˆFederated Learning, FLï¼‰ç‚ºé‡åŒ–ç ”ç©¶æ©Ÿæ§‹æä¾›äº†ä¸€ç¨®é©å‘½æ€§çš„å”ä½œæ–¹å¼ï¼Œèƒ½å¤ åœ¨ä¸å…±äº«åŸå§‹æ•¸æ“šçš„æƒ…æ³ä¸‹è¯åˆè¨“ç·´æ¨¡å‹ã€‚é€™ç‰¹åˆ¥é©åˆé‡‘èé ˜åŸŸï¼Œå› ç‚ºæ•¸æ“šæ•æ„Ÿæ€§å’Œç›£ç®¡è¦æ±‚åš´æ ¼ã€‚ç ”ç©¶è¡¨æ˜ï¼Œé€šéçµåˆåŒæ…‹åŠ å¯†ã€å®‰å…¨èšåˆç­‰éš±ç§ä¿è­·æŠ€è¡“ï¼Œè¯é‚¦å­¸ç¿’å¯åœ¨é‡åŒ–ç­–ç•¥å„ªåŒ–ã€é¢¨éšªç®¡ç†ã€å¸‚å ´å¾®çµæ§‹åˆ†æç­‰å¤šå€‹å ´æ™¯ä¸­å¯¦ç¾é¡¯è‘—åƒ¹å€¼ã€‚ä¸»è¦æŒ‘æˆ°åœ¨æ–¼é€šä¿¡æˆæœ¬ã€æ•¸æ“šç•°æ§‹æ€§å’Œç³»çµ±å®‰å…¨æ€§ï¼Œä½†é€šéåˆé©çš„æ¡†æ¶é¸æ“‡å’Œæ¶æ§‹è¨­è¨ˆå¯ä»¥æœ‰æ•ˆç·©è§£ã€‚</p>

<p>---</p>

<h2>ä¸€ã€æ‡‰ç”¨å ´æ™¯åˆ†æ</h2>

<h3>1.1 é‡åŒ–ç­–ç•¥å„ªåŒ–</h3>

<strong>å ´æ™¯æè¿°ï¼š</strong>
å¤šå®¶åŸºé‡‘å…¬å¸å„è‡ªæŒæœ‰æ­·å²äº¤æ˜“æ•¸æ“šï¼Œå¸Œæœ›è¯åˆæ”¹é€²é‡åŒ–äº¤æ˜“ç­–ç•¥è€Œä¸æ´©éœ²å…·é«”æŒå€‰å’Œäº¤æ˜“ç´°ç¯€ã€‚

<strong>å¯¦æ–½æ–¹å¼ï¼š</strong>
- å„æ©Ÿæ§‹æœ¬åœ°è¨“ç·´æ¨¡å‹ï¼ˆå¦‚é æ¸¬è‚¡åƒ¹è¶¨å‹¢çš„LSTMï¼‰
- å…±äº«æ¨¡å‹åƒæ•¸è€ŒéåŸå§‹æ•¸æ“š
- ä¸­å¿ƒæœå‹™å™¨èšåˆå„å®¢æˆ¶ç«¯çš„æ¢¯åº¦æ›´æ–°

<strong>å„ªå‹¢ï¼š</strong>
- æ•¸æ“šä¸å‡ºæœ¬åœ°ï¼Œç¬¦åˆç›£ç®¡è¦æ±‚
- è¯åˆæ•¸æ“šè¦æ¨¡æ›´å¤§ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›æ›´å¼·
- ä¿æŒæ©Ÿæ§‹çš„ç«¶çˆ­å„ªå‹¢ï¼ˆå…·é«”ç­–ç•¥ç´°ç¯€ä¸å¤–æ´©ï¼‰

<h3>1.2 é¢¨éšªç®¡ç†æ¨¡å‹</h3>

<strong>å ´æ™¯æè¿°ï¼š</strong>
è·¨æ©Ÿæ§‹é¢¨éšªè©•ä¼°ï¼Œéœ€è¦èšåˆå¤šæºæ•¸æ“šï¼ˆä¿¡ç”¨é¢¨éšªã€å¸‚å ´é¢¨éšªã€æ“ä½œé¢¨éšªï¼‰ã€‚

<strong>æ‡‰ç”¨å¯¦ä¾‹ï¼š</strong>
<pre><code>æœ¬åœ°æ•¸æ“šé¡å‹ï¼š
- æ©Ÿæ§‹Aï¼šè²¸æ¬¾é•ç´„è¨˜éŒ„
- æ©Ÿæ§‹Bï¼šå¸‚å ´æ³¢å‹•ç‡æ•¸æ“š
- æ©Ÿæ§‹Cï¼šäº¤æ˜“ç•°å¸¸æª¢æ¸¬è¨˜éŒ„

<p>è¯åˆç›®æ¨™ï¼šæ§‹å»ºç¶œåˆé¢¨éšªè©•åˆ†æ¨¡å‹
</code></pre></p>

<h3>1.3 å¸‚å ´å¾®çµæ§‹åˆ†æ</h3>

<strong>å ´æ™¯æè¿°ï¼š</strong>
ä¸åŒäº¤æ˜“æ‰€æˆ–äº¤æ˜“å•†å…±äº«è¨‚å–®æµåˆ†æèƒ½åŠ›ï¼Œæ”¹å–„åŸ·è¡Œç®—æ³•ã€‚

<strong>æŠ€è¡“è¦é»ï¼š</strong>
- é«˜é »æ•¸æ“šè™•ç†è¦æ±‚ä½å»¶é²é€šä¿¡
- éœ€è¦å·®åˆ†éš±ç§ä¿è­·äº¤æ˜“æ¨¡å¼
- ç•°æ­¥èšåˆæ©Ÿåˆ¶æ‡‰å°æ™‚å€å·®ç•°

<h3>1.4 åæ¬ºè©æª¢æ¸¬</h3>

<strong>å ´æ™¯æè¿°ï¼š</strong>
å¤šæ©Ÿæ§‹å…±åŒè¨“ç·´é‡‘èæ¬ºè©æª¢æ¸¬æ¨¡å‹ï¼Œåˆ©ç”¨è·¨æ©Ÿæ§‹æ¡ˆä¾‹åº«æå‡æª¢æ¸¬ç‡ã€‚

<strong>ç‰¹é»ï¼š</strong>
- ä¸å¹³è¡¡æ•¸æ“šå•é¡Œåš´é‡ï¼ˆæ¬ºè©æ¨£æœ¬ç¨€å°‘ï¼‰
- è¯é‚¦å­¸ç¿’å¯æ“´å¤§æœ‰æ•ˆæ¨£æœ¬æ± 
- å¯¦æ™‚æª¢æ¸¬è¦æ±‚æ¨¡å‹è¼•é‡åŒ–

<p>---</p>

<h2>äºŒã€è·¨æ©Ÿæ§‹å”ä½œæ¨¡å‹</h2>

<h3>2.1 åŸºæœ¬æ¶æ§‹</h3>

<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ©Ÿæ§‹ A    â”‚         â”‚   æ©Ÿæ§‹ B    â”‚         â”‚   æ©Ÿæ§‹ C    â”‚
â”‚  (Client)   â”‚         â”‚  (Client)   â”‚         â”‚  (Client)   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚                       â”‚
       â”‚  æ¨¡å‹åƒæ•¸æ›´æ–°          â”‚  æ¨¡å‹åƒæ•¸æ›´æ–°          â”‚  æ¨¡å‹åƒæ•¸æ›´æ–°
       â”‚                       â”‚                       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                       â”‚
                   â–¼                       â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚        èšåˆæœå‹™å™¨ (Aggregator)        â”‚
         â”‚  - åŠ å¯†èšåˆ                           â”‚
         â”‚  - æ¨¡å‹åƒæ•¸å¹³å‡                       â”‚
         â”‚  - å®‰å…¨é©—è­‰                           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚  å…¨å±€æ¨¡å‹
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         ä¸‹ä¸€ä»£å…¨å±€æ¨¡å‹                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>

<h3>2.2 å”ä½œæ¨¡å¼</h3>

<h4>æ¨¡å¼ä¸€ï¼šä¸­å¿ƒåŒ–è¯é‚¦å­¸ç¿’ï¼ˆCentralized FLï¼‰</h4>
- <strong>ç‰¹é»ï¼š</strong> ä¸­å¿ƒæœå‹™å™¨å”èª¿èšåˆ
- <strong>é©ç”¨ï¼š</strong> æ©Ÿæ§‹æ•¸é‡æœ‰é™ï¼ˆ<20ï¼‰ï¼Œä¿¡ä»»ä¸­å¿ƒæœå‹™å™¨
- <strong>å„ªå‹¢ï¼š</strong> å¯¦ç¾ç°¡å–®ï¼Œæ•ˆç‡é«˜

<h4>æ¨¡å¼äºŒï¼šå»ä¸­å¿ƒåŒ–è¯é‚¦å­¸ç¿’ï¼ˆDecentralized FLï¼‰</h4>
- <strong>ç‰¹é»ï¼š</strong> å®¢æˆ¶ç«¯ä¹‹é–“ç›´æ¥é€šä¿¡ï¼Œç„¡ä¸­å¿ƒæœå‹™å™¨
- <strong>é©ç”¨ï¼š</strong> å°ç­‰å”ä½œï¼Œæ©Ÿæ§‹é–“ç›´æ¥ä¿¡ä»»
- <strong>å„ªå‹¢ï¼š</strong> æ›´é«˜éš±ç§æ€§ï¼ŒæŠ—å–®é»æ•…éšœ

<h4>æ¨¡å¼ä¸‰ï¼šåˆ†å±¤è¯é‚¦å­¸ç¿’ï¼ˆHierarchical FLï¼‰</h4>
- <strong>ç‰¹é»ï¼š</strong> å¤šå±¤èšåˆï¼ˆåœ°å€â†’åœ‹å®¶â†’å…¨çƒï¼‰
- <strong>é©ç”¨ï¼š</strong> è·¨åœ°åŸŸã€è·¨ç›£ç®¡å€åŸŸçš„å¤§å‹é‡‘èæ©Ÿæ§‹
- <strong>å„ªå‹¢ï¼š</strong> é™ä½é€šä¿¡æˆæœ¬ï¼Œç¬¦åˆæœ¬åœ°ç›£ç®¡

<h3>2.3 æ•¸æ“šä¸é›¢æœ¬åœ°ï¼ˆData-at-Restï¼‰</h3>

<strong>æ ¸å¿ƒåŸå‰‡ï¼š</strong>
1. åŸå§‹æ•¸æ“šæ°¸ä¸é›¢é–‹æ©Ÿæ§‹é‚Šç•Œ
2. åƒ…å‚³è¼¸æ¨¡å‹æ›´æ–°ï¼ˆæ¢¯åº¦æˆ–åƒæ•¸ï¼‰
3. é€šéåŠ å¯†æŠ€è¡“ä¿è­·å‚³è¼¸éç¨‹
4. å¯é¸ï¼šåœ¨æœ¬åœ°æ·»åŠ å·®åˆ†éš±ç§å™ªè²

<strong>å¯¦æ–½ä¿éšœï¼š</strong>
<pre><code><h1>åƒ…å…±äº«æ¨¡å‹åƒæ•¸çš„ç¤ºä¾‹</h1>
def get_model_update(local_model, global_model):
    """
    è¨ˆç®—æœ¬åœ°æ¨¡å‹æ›´æ–°ï¼ˆåƒ…è¿”å›åƒæ•¸å·®ç•°ï¼‰
    """
    update = {}
    for param_name in local_model.state_dict():
        local_param = local_model.state_dict()[param_name]
        global_param = global_model.state_dict()[param_name]
        update[param_name] = local_param - global_param
    return update  # åƒ…å‚³è¼¸å·®ç•°ï¼Œä¸æ´©éœ²åŸå§‹æ•¸æ“š
</code></pre>

<p>---</p>

<h2>ä¸‰ã€æŠ€è¡“æŒ‘æˆ°åˆ†æ</h2>

<h3>3.1 é€šä¿¡æˆæœ¬</h3>

<strong>å•é¡Œåš´é‡æ€§ï¼š</strong> é«˜

<strong>æŒ‘æˆ°æè¿°ï¼š</strong>
- é‡‘èæ•¸æ“šé€šå¸¸é«˜ç¶­åº¦ï¼ˆå¤šç‰¹å¾µï¼‰
- æ¨¡å‹åƒæ•¸é‡å¤§ï¼ˆæ·±åº¦å­¸ç¿’æ¨¡å‹ï¼‰
- é »ç¹çš„å¾€è¿”é€šä¿¡å¢åŠ å»¶é²

<strong>é‡åŒ–åˆ†æï¼š</strong>
<pre><code>å‡è¨­å ´æ™¯ï¼š
- 10å€‹æ©Ÿæ§‹åƒèˆ‡
- æ¯è¼ªè¨“ç·´å‚³è¼¸æ¨¡å‹ï¼š100MB
- è¨“ç·´è¼ªæ•¸ï¼š100è¼ª
- ç¸½é€šä¿¡é‡ï¼š10 Ã— 100MB Ã— 100 = 100GB

<p>é€šä¿¡æˆæœ¬ä¼°ç®—ï¼š
- å¸¶å¯¬æˆæœ¬ï¼š~$0.05/GB â†’ $5
- å»¶é²å½±éŸ¿ï¼šæ¯è¼ª2-5ç§’ï¼ˆåŠ å¯†+å‚³è¼¸ï¼‰
</code></pre></p>

<strong>è§£æ±ºæ–¹æ¡ˆï¼š</strong>

<table>
<tr> æ¨¡å‹å£“ç¸® <td>æ¬Šé‡é‡åŒ–ï¼ˆ32ä½â†’8ä½ï¼‰</td> å£“ç¸®ç‡75% |
<td>å·®åˆ†æ›´æ–°</td> åƒ…å‚³è¼¸è®ŠåŒ–è¶…éé–¾å€¼çš„æ¬Šé‡ <td>å£“ç¸®ç‡50-90%</td>
<td>å±€éƒ¨è¨“ç·´</td> æœ¬åœ°å¤šè¼ªå¾Œå†åŒæ­¥ <td>é€šä¿¡é »ç‡é™ä½90%</td>
<td>æ¢¯åº¦ç¨€ç–åŒ–</td> åƒ…å‚³è¼¸Top-Ké‡è¦æ¢¯åº¦ <td>å£“ç¸®ç‡70%</td>

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼šæ¨¡å‹å£“ç¸®</strong>
<pre><code>import torch

<p>def compress_gradients(gradients, quantization_bits=8):
    """
    æ¬Šé‡é‡åŒ–å£“ç¸®
    """
    compressed = {}
    for name, grad in gradients.items():
        # è¨ˆç®—é‡åŒ–ç¯„åœ
        min_val, max_val = grad.min(), grad.max()
        scale = (max_val - min_val) / (2**quantization_bits - 1)</p>

<p>        # é‡åŒ–
        quantized = ((grad - min_val) / scale).round().to(torch.uint8)</p>

<p>        # å­˜å„²å£“ç¸®æ•¸æ“š
        compressed[name] = {
            'quantized': quantized,
            'min': min_val,
            'scale': scale
        }</p>

<p>    return compressed</p>

<p>def decompress_gradients(compressed):
    """
    è§£å£“ç¸®æ¢¯åº¦
    """
    gradients = {}
    for name, data in compressed.items():
        # åé‡åŒ–
        grad = data['quantized'].float() * data['scale'] + data['min']
        gradients[name] = grad</p>

<p>    return gradients
</code></pre></p>

<h3>3.2 ç•°æ§‹æ•¸æ“š</h3>

<strong>å•é¡Œåš´é‡æ€§ï¼š</strong> é«˜

<strong>æŒ‘æˆ°æè¿°ï¼š</strong>
- <strong>Non-IIDæ•¸æ“šï¼š</strong> å„æ©Ÿæ§‹æ•¸æ“šåˆ†å¸ƒå·®ç•°å¤§
- <strong>ç‰¹å¾µç•°æ§‹ï¼š</strong> ä¸åŒæ©Ÿæ§‹æ¡ç”¨ä¸åŒç‰¹å¾µå·¥ç¨‹
- <strong>æ¨™ç±¤ç•°æ§‹ï¼š</strong> å®šç¾©å¯èƒ½ä¸ä¸€è‡´ï¼ˆå¦‚é¢¨éšªç­‰ç´šï¼‰

<strong>å…·é«”è¡¨ç¾ï¼š</strong>
<pre><code>æ©Ÿæ§‹Aæ•¸æ“šç‰¹é»ï¼š
- å¸‚å ´ï¼šäºæ´²è‚¡ç¥¨
- ç‰¹å¾µï¼šæŠ€è¡“æŒ‡æ¨™ï¼ˆRSI, MACDï¼‰
- æ¨™ç±¤ï¼šæ¼²è·Œåˆ†é¡

<p>æ©Ÿæ§‹Bæ•¸æ“šç‰¹é»ï¼š
- å¸‚å ´ï¼šç¾åœ‹æœŸè²¨
- ç‰¹å¾µï¼šåŸºæœ¬é¢æ•¸æ“šï¼ˆPE, ROEï¼‰
- æ¨™ç±¤ï¼šå›å ±ç‡å›æ­¸
</code></pre></p>

<strong>è§£æ±ºæ–¹æ¡ˆï¼š</strong>

<p>1. <strong>å®¢æˆ¶ç«¯åŠ æ¬Šèšåˆ</strong>
<pre><code>def weighted_fedavg(updates, client_weights):
    """
    æ ¹æ“šå®¢æˆ¶ç«¯æ•¸æ“šé‡åŠ æ¬Šèšåˆ
    """
    aggregated = {}
    for param_name in updates[0].keys():
        weighted_sum = sum(
            updates[i][param_name] * client_weights[i]
            for i in range(len(updates))
        )
        aggregated[param_name] = weighted_sum / sum(client_weights)</p>

<p>    return aggregated</p>

<h1>å®¢æˆ¶ç«¯æ¬Šé‡å¯åŸºæ–¼ï¼š</h1>
<h1>- æ•¸æ“šé›†å¤§å°</h1>
<h1>- æ¨¡å‹è³ªé‡ï¼ˆé©—è­‰é›†æº–ç¢ºç‡ï¼‰</h1>
<h1>- æ•¸æ“šå¤šæ¨£æ€§ï¼ˆç†µå€¼ï¼‰</h1>
</code></pre>

<p>2. <strong>çŸ¥è­˜è’¸é¤¾ï¼ˆKnowledge Distillationï¼‰</strong>
<pre><code>def knowledge_distillation_aggregation(local_models, global_model, unlabeled_data):
    """
    ä½¿ç”¨çŸ¥è­˜è’¸é¤¾èšåˆç•°æ§‹æ¨¡å‹
    """
    # æ”¶é›†å„æœ¬åœ°æ¨¡å‹çš„é æ¸¬ï¼ˆè»Ÿæ¨™ç±¤ï¼‰
    soft_labels = []
    for model in local_models:
        with torch.no_grad():
            logits = model(unlabeled_data)
            soft_labels.append(torch.softmax(logits / 3, dim=1))</p>

<p>    # å¹³å‡è»Ÿæ¨™ç±¤
    avg_soft_labels = torch.stack(soft_labels).mean(dim=0)</p>

<p>    # ä½¿ç”¨è»Ÿæ¨™ç±¤è¨“ç·´å…¨å±€æ¨¡å‹
    global_model_logits = global_model(unlabeled_data)
    distillation_loss = F.kl_div(
        F.log_softmax(global_model_logits / 3, dim=1),
        avg_soft_labels,
        reduction='batchmean'
    )</p>

<p>    return distillation_loss
</code></pre></p>

<p>3. <strong>è‡ªé©æ‡‰èšåˆç­–ç•¥</strong>
<pre><code>class AdaptiveAggregator:
    def __init__(self, learning_rate=0.1):
        self.client_performance = {}  # è¨˜éŒ„å®¢æˆ¶ç«¯æ­·å²è¡¨ç¾</p>

<p>    def compute_weights(self, client_ids):
        """
        æ ¹æ“šæ­·å²è¡¨ç¾è‡ªé©æ‡‰è¨ˆç®—èšåˆæ¬Šé‡
        """
        weights = []
        for client_id in client_ids:
            if client_id in self.client_performance:
                # åŸºæ–¼æ­·å²é©—è­‰æ€§èƒ½
                perf = self.client_performance[client_id]
                weight = softmax(perf)[-1]  # æœ€æ–°æ€§èƒ½
            else:
                weight = 1.0 / len(client_ids)  # å¹³å‡åˆ†é…
            weights.append(weight)</p>

<p>        # æ­¸ä¸€åŒ–
        total = sum(weights)
        return [w / total for w in weights]</p>

<p>    def update_performance(self, client_id, validation_score):
        """
        æ›´æ–°å®¢æˆ¶ç«¯æ€§èƒ½è¨˜éŒ„
        """
        if client_id not in self.client_performance:
            self.client_performance[client_id] = []
        self.client_performance[client_id].append(validation_score)
</code></pre></p>

<h3>3.3 å®‰å…¨æ€§æŒ‘æˆ°</h3>

<strong>å•é¡Œåš´é‡æ€§ï¼š</strong> æ¥µé«˜

<strong>ä¸»è¦å¨è„…ï¼š</strong>

<table>
<tr> æ¨¡å‹åæ¨æ”»æ“Š <td>é€šéæ¨¡å‹åƒæ•¸åæ¨åŸå§‹æ•¸æ“š</td> æ•¸æ“šæ´©éœ² |
<td>æƒ¡æ„å®¢æˆ¶ç«¯</td> æŠ•æ¯’æ”»æ“Šï¼Œæå®³å…¨å±€æ¨¡å‹ <td>æ¨¡å‹å¤±æ•ˆ</td>
<td>ä¸­é–“äººæ”»æ“Š</td> æ””æˆªæˆ–ç¯¡æ”¹é€šä¿¡ <td>æ•¸æ“šå®Œæ•´æ€§</td>
<td>æˆå“¡æ¨ç†æ”»æ“Š</td> åˆ¤æ–·æŸæ¢æ•¸æ“šæ˜¯å¦åœ¨è¨“ç·´é›†ä¸­ <td>éš±ç§æ´©éœ²</td>

<strong>é˜²è­·æªæ–½ï¼š</strong>

<h4>3.3.1 å®‰å…¨å¤šæ–¹è¨ˆç®—ï¼ˆSecure Multi-Party Computationï¼‰</h4>

<pre><code><h1>å½ä»£ç¢¼ï¼šå®‰å…¨èšåˆç¤ºæ„</h1>
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography.hazmat.primitives import hashes

<p>class SecureAggregator:
    def __init__(self, clients):
        self.clients = clients
        self.pairs = self._generate_pairwise_keys()</p>

<p>    def _generate_pairwise_keys(self):
        """
        ç‚ºæ¯å°å®¢æˆ¶ç«¯ç”Ÿæˆå…±äº«å¯†é‘°
        """
        pairs = {}
        for i, client_a in enumerate(self.clients):
            for j, client_b in enumerate(self.clients):
                if i < j:
                    # å¯¦éš›æ‡‰ç”¨ä¸­ä½¿ç”¨Diffie-Hellman
                    pairs[(client_a, client_b)] = self._dh_key_exchange()
        return pairs</p>

<p>    def mask_update(self, client_id, update):
        """
        å®¢æˆ¶ç«¯æ·»åŠ æ©ç¢¼å¾Œä¸Šå‚³
        """
        masked = update.copy()</p>

<p>        # æ·»åŠ å°å…¶ä»–å®¢æˆ¶ç«¯çš„æ©ç¢¼
        for other_id in self.clients:
            if other_id != client_id:
                if (client_id, other_id) in self.pairs:
                    key = self.pairs[(client_id, other_id)]
                    mask = self._generate_mask(key)
                    masked = masked + mask
                elif (other_id, client_id) in self.pairs:
                    key = self.pairs[(other_id, client_id)]
                    mask = self._generate_mask(key)
                    masked = masked - mask</p>

<p>        return masked</p>

<p>    def unmask_and_aggregate(self, masked_updates):
        """
        æœå‹™å™¨èšåˆä¸¦å»é™¤æ©ç¢¼ï¼ˆå› æ©ç¢¼å’Œç‚ºé›¶ï¼‰
        """
        # ç›´æ¥å¹³å‡å³å¯ï¼Œæ©ç¢¼è‡ªå‹•æŠµæ¶ˆ
        aggregated = sum(masked_updates) / len(masked_updates)
        return aggregated
</code></pre></p>

<h4>3.3.2 å·®åˆ†éš±ç§ï¼ˆDifferential Privacyï¼‰</h4>

<pre><code>import numpy as np

<p>def add_dp_noise(gradients, noise_multiplier, sensitivity, clip_norm):
    """
    æ·»åŠ å·®åˆ†éš±ç§å™ªè²
    """
    clipped_gradients = {}</p>

<p>    # 1. æ¢¯åº¦è£å‰ª
    for name, grad in gradients.items():
        grad_norm = np.linalg.norm(grad)
        if grad_norm > clip_norm:
            grad = grad * (clip_norm / grad_norm)
        clipped_gradients[name] = grad</p>

<p>    # 2. æ·»åŠ æ‹‰æ™®æ‹‰æ–¯å™ªè²
    noisy_gradients = {}
    scale = sensitivity * noise_multiplier
    for name, grad in clipped_gradients.items():
        noise = np.random.laplace(0, scale, grad.shape)
        noisy_gradients[name] = grad + noise</p>

<p>    return noisy_gradients</p>

<h1>ä½¿ç”¨ç¤ºä¾‹</h1>
dp_updates = add_dp_noise(
    gradients=client_gradients,
    noise_multiplier=0.5,  # å¹³è¡¡éš±ç§å’Œæº–ç¢ºç‡
    sensitivity=1.0,       # æ¢¯åº¦è£å‰ªé–¾å€¼
    clip_norm=1.0          # æ¢¯åº¦è£å‰ªé–¾å€¼
)
</code></pre>

<h4>3.3.3 æƒ¡æ„å®¢æˆ¶ç«¯æª¢æ¸¬</h4>

<pre><code>def detect_malicious_clients(updates, baseline, threshold=3.0):
    """
    åŸºæ–¼çµ±è¨ˆç•°å¸¸æª¢æ¸¬æƒ¡æ„å®¢æˆ¶ç«¯
    """
    # è¨ˆç®—æ›´æ–°çš„çµ±è¨ˆé‡
    update_norms = [np.linalg.norm(update) for update in updates]

<p>    # Z-scoreç•°å¸¸æª¢æ¸¬
    mean_norm = np.mean(update_norms)
    std_norm = np.std(update_norms)</p>

<p>    malicious_indices = []
    for i, norm in enumerate(update_norms):
        z_score = abs(norm - mean_norm) / (std_norm + 1e-6)
        if z_score > threshold:
            malicious_indices.append(i)</p>

<p>    return malicious_indices</p>

<p>def krum_aggregation(updates, num_malicious=1):
    """
    Krumèšåˆï¼šæŠµæŠ—æœ€å¤šfå€‹æƒ¡æ„å®¢æˆ¶ç«¯
    """
    # è¨ˆç®—æˆå°è·é›¢
    n = len(updates)
    distances = np.zeros((n, n))</p>

<p>    for i in range(n):
        for j in range(i+1, n):
            dist = np.linalg.norm(updates[i] - updates[j])
            distances[i][j] = distances[j][i] = dist</p>

<p>    # ç‚ºæ¯å€‹å®¢æˆ¶ç«¯è¨ˆç®—åˆ°æœ€è¿‘n-f-1å€‹å®¢æˆ¶ç«¯çš„è·é›¢å’Œ
    scores = []
    for i in range(n):
        sorted_dist = np.sort(distances[i])
        score = sum(sorted_dist[:n - num_malicious - 1])
        scores.append(score)</p>

<p>    # é¸æ“‡åˆ†æ•¸æœ€å°çš„å®¢æˆ¶ç«¯æ›´æ–°
    best_client = np.argmin(scores)
    return updates[best_client]
</code></pre></p>

<p>---</p>

<h2>å››ã€ç›¸é—œæ¡†æ¶èª¿æŸ¥</h2>

<h3>4.1 PySyft</h3>

<strong>æ¦‚è¿°ï¼š</strong>
- é–‹ç™¼è€…ï¼šOpenMined
- ç‰¹é»ï¼šéš±ç§ä¿è­·æ©Ÿå™¨å­¸ç¿’æ¡†æ¶
- æ ¸å¿ƒï¼šæ”¯æŒè¯é‚¦å­¸ç¿’ã€å·®åˆ†éš±ç§ã€åŒæ…‹åŠ å¯†

<strong>å„ªå‹¢ï¼š</strong>
- æ·±åº¦é›†æˆPyTorch
- è±å¯Œçš„åŠ å¯†åº«
- æ´»èºçš„ç¤¾å€æ”¯æŒ

<strong>åŠ£å‹¢ï¼š</strong>
- APIè¼ƒè¤‡é›œï¼Œå­¸ç¿’æ›²ç·šé™¡å³­
- æ€§èƒ½å„ªåŒ–ä¸å¤ æˆç†Ÿ
- æ–‡æª”æœ‰æ™‚ä¸å¤ å®Œæ•´

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼š</strong>
<pre><code>import torch
import syft as sy

<h1>å‰µå»ºè™›æ“¬å·¥ä½œç¯€é»</h1>
hook = sy.TorchHook(torch)
alice = sy.VirtualWorker(hook, id="alice")
bob = sy.VirtualWorker(hook, id="bob")
charlie = sy.VirtualWorker(hook, id="charlie")

<h1>åˆ†ç™¼æ•¸æ“š</h1>
data = torch.tensor([[1., 1], [2, 2], [3, 3]])
targets = torch.tensor([[1.], [2], [3]])

<p>data = data.send(alice)
targets = targets.send(alice)</p>

<h1>è¯é‚¦è¨“ç·´</h1>
model = torch.nn.Linear(2, 1)
opt = torch.optim.SGD(model.parameters(), lr=0.1)

<p>for i in range(10):
    # æœ¬åœ°è¨ˆç®—
    opt.zero_grad()
    pred = model(data)
    loss = ((pred - targets)**2).sum()</p>

<p>    # åå‘å‚³æ’­
    loss.backward()</p>

<p>    # ç²å–æ¢¯åº¦ï¼ˆä»ç„¶åœ¨é ç¨‹ï¼‰
    opt.step()</p>

<p>    # èšåˆï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æœƒæœ‰å¤šå€‹å®¢æˆ¶ç«¯ï¼‰
</code></pre></p>

<h3>4.2 Flower</h3>

<strong>æ¦‚è¿°ï¼š</strong>
- é–‹ç™¼è€…ï¼šAdapï¼ˆå‰Intel Labsï¼‰
- ç‰¹é»ï¼šå°ˆæ³¨æ–¼è¯é‚¦å­¸ç¿’çš„æ¡†æ¶
- æ ¸å¿ƒï¼šå¹³å°ç„¡é—œï¼Œæ”¯æŒå¤šç¨®æ©Ÿå™¨å­¸ç¿’æ¡†æ¶

<strong>å„ªå‹¢ï¼š</strong>
- ç°¡å–®æ˜“ç”¨çš„API
- é«˜åº¦å¯å®šåˆ¶
- æ”¯æŒç•°æ­¥è¯é‚¦å­¸ç¿’
- ç”Ÿç”¢å°±ç·’ï¼ˆè¢«å¤šå®¶ä¼æ¥­ä½¿ç”¨ï¼‰

<strong>åŠ£å‹¢ï¼š</strong>
- ç›¸å°è¼ƒæ–°ï¼Œç”Ÿæ…‹è¼ƒå°
- æŸäº›é«˜ç´šç‰¹æ€§æ–‡æª”ä¸å¤ è©³ç´°

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼š</strong>
<pre><code><h1>server.py</h1>
import flwr as fl

<h1>å®šç¾©èšåˆç­–ç•¥</h1>
strategy = fl.server.strategy.FedAvg(
    min_fit_clients=3,
    min_evaluate_clients=3,
    min_available_clients=3,
)

<h1>å•Ÿå‹•æœå‹™å™¨</h1>
fl.server.start_server(
    server_address="0.0.0.0:8080",
    config=fl.server.ServerConfig(num_rounds=10),
    strategy=strategy,
)

<h1>client.py</h1>
import flwr as fl
from client import QuantNetClient

<h1>å•Ÿå‹•å®¢æˆ¶ç«¯</h1>
fl.client.start_numpy_client(
    server_address="localhost:8080",
    client=QuantNetClient(),
)

<h1>client.py ä¸­çš„å®¢æˆ¶ç«¯å¯¦ç¾</h1>
class QuantNetClient(fl.client.NumPyClient):
    def __init__(self):
        self.model = load_local_model()
        self.x_train, self.y_train = load_local_data()

<p>    def get_parameters(self):
        return self.model.get_weights()</p>

<p>    def fit(self, parameters, config):
        self.model.set_weights(parameters)</p>

<p>        # æœ¬åœ°è¨“ç·´
        self.model.fit(self.x_train, self.y_train, epochs=5)</p>

<p>        return self.model.get_weights(), len(self.x_train), {}</p>

<p>    def evaluate(self, parameters, config):
        self.model.set_weights(parameters)
        loss, accuracy = self.model.evaluate(self.x_test, self.y_test)
        return loss, len(self.x_test), {"accuracy": accuracy}
</code></pre></p>

<h3>4.3 TensorFlow Federated (TFF)</h3>

<strong>æ¦‚è¿°ï¼š</strong>
- é–‹ç™¼è€…ï¼šGoogle
- ç‰¹é»ï¼šç«¯åˆ°ç«¯çš„è¯é‚¦å­¸ç¿’å¹³å°
- æ ¸å¿ƒï¼šå°ˆé–€ç‚ºè¯é‚¦å­¸ç¿’è¨­è¨ˆçš„è¨ˆç®—æ¡†æ¶

<strong>å„ªå‹¢ï¼š</strong>
- Googleæ”¯æŒï¼Œç©©å®šæ€§é«˜
- è±å¯Œçš„æ•™ç¨‹å’Œæ–‡æª”
- å…§ç½®å¤šç¨®è¯é‚¦ç®—æ³•
- æ¨¡æ“¬å·¥å…·å®Œå–„

<strong>åŠ£å‹¢ï¼š</strong>
- åƒ…æ”¯æŒTensorFlowç”Ÿæ…‹
- APIæŠ½è±¡åº¦è¼ƒé«˜ï¼Œéˆæ´»æ€§æœ‰é™
- å¤§å‹æ¡†æ¶ï¼Œå­¸ç¿’æˆæœ¬è¼ƒé«˜

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼š</strong>
<pre><code>import tensorflow as tf
import tensorflow_federated as tff

<h1>å®šç¾©æ¨¡å‹</h1>
def create_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(1)
    ])
    return model

<h1>è½‰æ›ç‚ºTFFæ¨¡å‹</h1>
def model_fn():
    keras_model = create_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=preprocessed_example_dataset.element_spec,
        loss=tf.keras.losses.MeanSquaredError(),
        metrics=[tf.keras.metrics.MeanAbsoluteError()]
    )

<h1>å‰µå»ºè¯é‚¦å­¸ç¿’éç¨‹</h1>
iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.01),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(1.0)
)

<h1>åŸ·è¡Œè¯é‚¦è¨“ç·´</h1>
state = iterative_process.initialize()
for round_num in range(1, 11):
    state, metrics = iterative_process.next(state, federated_train_data)
    print(f'Round {round_num}: {metrics}')
</code></pre>

<h3>4.4 æ¡†æ¶æ¯”è¼ƒ</h3>

<table>
<tr> <strong>å­¸ç¿’æ›²ç·š</strong> <td>é™¡å³­</td> ä¸­ç­‰ <td>ä¸­ç­‰</td>
<td><strong>æ¡†æ¶æ”¯æŒ</strong></td> PyTorch <td>å¤šæ¡†æ¶</td> TensorFlow |
<td><strong>åŠ å¯†æ”¯æŒ</strong></td> è±å¯Œ <td>ä¸­ç­‰</td> æœ‰é™ |
<td><strong>ç”Ÿç”¢å°±ç·’</strong></td> ä¸­ç­‰ <td>é«˜</td> é«˜ |
<td><strong>æ–‡æª”è³ªé‡</strong></td> ä¸­ç­‰ <td>è‰¯å¥½</td> å„ªç§€ |
<td><strong>ç¤¾å€æ´»èºåº¦</strong></td> é«˜ <td>ä¸­ç­‰</td> é«˜ |
<td><strong>æ¨è–¦å ´æ™¯</strong></td> éš±ç§ç ”ç©¶ã€åŸå‹ <td>ç”Ÿç”¢éƒ¨ç½²ã€å¿«é€Ÿé–‹ç™¼</td> TFç”Ÿæ…‹ã€ç ”ç©¶ |

<strong>æ¨è–¦é¸æ“‡ï¼š</strong>
- <strong>ç ”ç©¶/åŸå‹ï¼š</strong> PySyftï¼ˆè±å¯Œçš„éš±ç§æŠ€è¡“ï¼‰
- <strong>ç”Ÿç”¢ç’°å¢ƒï¼š</strong> Flowerï¼ˆç©©å®šã€å¯å®šåˆ¶ï¼‰
- <strong>TensorFlowç”¨æˆ¶ï¼š</strong> TFFï¼ˆæ·±åº¦é›†æˆï¼‰

<p>---</p>

<h2>äº”ã€é‡‘èæ•¸æ“šéš±ç§ä¿è­·æŠ€è¡“</h2>

<h3>5.1 åŒæ…‹åŠ å¯†</h3>

<strong>åŸç†ï¼š</strong>
å…è¨±åœ¨åŠ å¯†æ•¸æ“šä¸Šç›´æ¥é€²è¡Œè¨ˆç®—ï¼Œè§£å¯†å¾Œçµæœç­‰æ–¼åœ¨åŸå§‹æ•¸æ“šä¸Šè¨ˆç®—çš„çµæœã€‚

<strong>é‡‘èæ‡‰ç”¨å ´æ™¯ï¼š</strong>
- å®‰å…¨èšåˆï¼šèšåˆåŠ å¯†çš„æ¨¡å‹æ›´æ–°
- éš±ç§æŸ¥è©¢ï¼šåœ¨ä¸æš´éœ²æ•¸æ“šæƒ…æ³ä¸‹è¨ˆç®—é¢¨éšªæŒ‡æ¨™
- å®‰å…¨å¤šæ–¹è¨ˆç®—ï¼šè¯åˆçµ±è¨ˆåˆ†æ

<strong>æŒ‘æˆ°ï¼š</strong>
- è¨ˆç®—é–‹éŠ·å¤§ï¼ˆ100-1000å€æ…¢ï¼‰
- é€šè¨Šé–‹éŠ·å¤§ï¼ˆå¯†æ–‡é«”ç©å¤§ï¼‰
- æŸäº›æ“ä½œä¸æ”¯æŒï¼ˆå¦‚æ¯”è¼ƒã€åˆ†æ”¯ï¼‰

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼ˆä½¿ç”¨PaillieråŠ å¯†ï¼‰ï¼š</strong>
<pre><code>import numpy as np
from phe import paillier

<p>class HomomorphicAggregator:
    def __init__(self):
        # ç”Ÿæˆå…¬é‘°å’Œç§é‘°
        self.public_key, self.private_key = paillier.generate_paillier_keypair()</p>

<p>    def encrypt_update(self, update):
        """
        å®¢æˆ¶ç«¯åŠ å¯†æ¨¡å‹æ›´æ–°
        """
        encrypted = {}
        for name, param in update.items():
            encrypted[name] = self.public_key.encrypt(param)
        return encrypted</p>

<p>    def aggregate_encrypted(self, encrypted_updates):
        """
        åœ¨åŠ å¯†ç‹€æ…‹ä¸‹èšåˆï¼ˆæœå‹™ç«¯ç„¡éœ€ç§é‘°ï¼‰
        """
        n_clients = len(encrypted_updates)</p>

<p>        # å°‡æ‰€æœ‰åŠ å¯†æ›´æ–°ç›¸åŠ 
        sum_encrypted = {}
        for name in encrypted_updates[0].keys():
            # å¯†æ–‡åŠ æ³•ï¼ˆåœ¨åŠ å¯†åŸŸé€²è¡Œï¼‰
            sum_encrypted[name] = sum(
                enc[name] for enc in encrypted_updates
            )</p>

<p>        # é™¤ä»¥å®¢æˆ¶ç«¯æ•¸é‡ï¼ˆéœ€è¦å¯†æ–‡é™¤æ³•æ”¯æŒï¼‰
        # å¯¦éš›æ‡‰ç”¨ä¸­å¯èƒ½éœ€è¦å…¶ä»–æŠ€è¡“æˆ–è¿‘ä¼¼
        averaged = {}
        for name, enc_value in sum_encrypted.items():
            # Paillieræ”¯æŒå¯†æ–‡èˆ‡æ˜æ–‡ä¹˜æ³•
            # å°‡1/nä½œç‚ºæ˜æ–‡ç›¸ä¹˜ç­‰æ–¼é™¤ä»¥n
            averaged[name] = enc_value * (1.0 / n_clients)</p>

<p>        return averaged</p>

<p>    def decrypt_aggregated(self, aggregated_encrypted):
        """
        è§£å¯†èšåˆçµæœ
        """
        decrypted = {}
        for name, enc_value in aggregated_encrypted.items():
            decrypted[name] = self.private_key.decrypt(enc_value)
        return decrypted</p>

<h1>ä½¿ç”¨æµç¨‹</h1>
<h1>æœå‹™å™¨ç«¯</h1>
aggregator = HomomorphicAggregator()

<h1>å®¢æˆ¶ç«¯A</h1>
update_a = {"weight1": np.array([1.0, 2.0]), "bias1": np.array([0.5])}
encrypted_a = aggregator.encrypt_update(update_a)

<h1>å®¢æˆ¶ç«¯B</h1>
update_b = {"weight1": np.array([3.0, 4.0]), "bias1": np.array([1.5])}
encrypted_b = aggregator.encrypt_update(update_b)

<h1>èšåˆï¼ˆç„¡éœ€è§£å¯†ï¼‰</h1>
encrypted_avg = aggregator.aggregate_encrypted([encrypted_a, encrypted_b])

<h1>è§£å¯†</h1>
avg_update = aggregator.decrypt_aggregated(encrypted_avg)
print("Averaged update:", avg_update)
</code></pre>

<strong>å¯¦è¸å»ºè­°ï¼š</strong>
- æ··åˆä½¿ç”¨ï¼šé—œéµä¿¡æ¯åŒæ…‹åŠ å¯†ï¼Œå…¶ä»–ä½¿ç”¨å‚³çµ±åŠ å¯†
- æ‰¹è™•ç†ï¼šæ¸›å°‘åŠ å¯†æ“ä½œæ¬¡æ•¸
- ç¡¬ä»¶åŠ é€Ÿï¼šä½¿ç”¨GPU/FPGAåŠ é€ŸåŠ å¯†é‹ç®—
- è¿‘ä¼¼èšåˆï¼šæ¥å—å°å¹…ç²¾åº¦æå¤±æ›å–æ€§èƒ½

<h3>5.2 å®‰å…¨èšåˆï¼ˆSecure Aggregationï¼‰</h3>

<strong>åŸç†ï¼š</strong>
é€šéæ©ç¢¼æŠ€è¡“ç¢ºä¿æœå‹™å™¨åªèƒ½çœ‹åˆ°èšåˆå¾Œçš„çµæœï¼Œè€Œç„¡æ³•æ¨æ–·ä»»ä½•å–®å€‹å®¢æˆ¶ç«¯çš„è²¢ç»ã€‚

<strong>æ–¹æ¡ˆï¼š</strong>
1. <strong>åŸºæ–¼ç¥•å¯†å…±äº«ï¼š</strong> å°‡æ›´æ–°æ‹†åˆ†ç‚ºå¤šä»½ï¼Œåˆ†ç™¼åˆ°ä¸åŒç¯€é»
2. <strong>åŸºæ–¼é…å°æ©ç¢¼ï¼š</strong> å®¢æˆ¶ç«¯é–“äº’ç›¸ç”ŸæˆæŠµæ¶ˆçš„æ©ç¢¼
3. <strong>åŸºæ–¼é›²æœå‹™ï¼š</strong> ä½¿ç”¨å¯ä¿¡åŸ·è¡Œç’°å¢ƒï¼ˆTEEï¼‰

<strong>ä»£ç¢¼ç¤ºä¾‹ï¼šé…å°æ©ç¢¼æ–¹æ¡ˆ</strong>
<pre><code>import numpy as np
import hashlib
from cryptography.fernet import Fernet

<p>class PairedMaskAggregation:
    def __init__(self, clients):
        self.clients = clients
        self.keys = self._generate_pairwise_keys()</p>

<p>    def _generate_pairwise_keys(self):
        """
        ç‚ºæ¯å°å®¢æˆ¶ç«¯ç”Ÿæˆç¥•å¯†å¯†é‘°
        å¯¦éš›æ‡‰ç”¨ä¸­ä½¿ç”¨Diffie-Hellmanæˆ–TLS
        """
        keys = {}
        for i, client_a in enumerate(self.clients):
            for j, client_b in enumerate(self.clients):
                if i < j:
                    # ä½¿ç”¨å°ç¨±åŠ å¯†ç”Ÿæˆå½éš¨æ©Ÿæ©ç¢¼
                    key = Fernet.generate_key()
                    keys[(client_a, client_b)] = key
                    keys[(client_b, client_a)] = key
        return keys</p>

<p>    def _generate_mask(self, key, shape, seed=None):
        """
        ä½¿ç”¨å¯†é‘°ç”Ÿæˆç¢ºå®šæ€§éš¨æ©Ÿæ©ç¢¼
        """
        if seed is None:
            seed = np.random.randint(0, 2**32)</p>

<p>        # ä½¿ç”¨å¯†é‘°ç”Ÿæˆå½éš¨æ©Ÿæ•¸
        cipher = Fernet(key)
        seed_bytes = seed.to_bytes(4, 'big').ljust(16, b'\0')
        encrypted = cipher.encrypt(seed_bytes)</p>

<p>        # è½‰æ›ç‚ºéš¨æ©Ÿæ•¸
        hash_val = hashlib.sha256(encrypted).hexdigest()
        rng = np.random.RandomState(int(hash_val[:8], 16))</p>

<p>        return rng.randn(<em>shape) </em> 0.1  # æ©ç¢¼æ¨™æº–å·®ç‚º0.1</p>

<p>    def apply_masks(self, client_id, update, round_num):
        """
        å®¢æˆ¶ç«¯æ‡‰ç”¨æ©ç¢¼
        """
        masked_update = {}</p>

<p>        for name, param in update.items():
            mask = np.zeros_like(param)</p>

<p>            # å°æ¯å€‹å…¶ä»–å®¢æˆ¶ç«¯æ·»åŠ æ©ç¢¼
            for other_id in self.clients:
                if other_id == client_id:
                    continue</p>

<p>                # ä½¿ç”¨å®¢æˆ¶ç«¯å°çš„å¯†é‘°
                key = self.keys[(client_id, other_id)]
                mask = mask + self._generate_mask(key, param.shape, round_num)</p>

<p>            masked_update[name] = param + mask</p>

<p>        return masked_update</p>

<p>    def aggregate(self, masked_updates):
        """
        æœå‹™å™¨èšåˆï¼ˆæ©ç¢¼è‡ªå‹•æŠµæ¶ˆï¼‰
        """
        n_clients = len(masked_updates)</p>

<p>        # ç›´æ¥å¹³å‡
        aggregated = {}
        for name in masked_updates[0].keys():
            sum_param = sum(m[name] for m in masked_updates)
            aggregated[name] = sum_param / n_clients</p>

<p>        return aggregated</p>

<h1>ä½¿ç”¨ç¤ºä¾‹</h1>
clients = ["A", "B", "C"]
aggregator = PairedMaskAggregation(clients)

<h1>å®¢æˆ¶ç«¯A</h1>
update_a = {"weight": np.array([1.0, 2.0])}
masked_a = aggregator.apply_masks("A", update_a, round_num=1)

<h1>å®¢æˆ¶ç«¯B</h1>
update_b = {"weight": np.array([3.0, 4.0])}
masked_b = aggregator.apply_masks("B", update_b, round_num=1)

<h1>å®¢æˆ¶ç«¯C</h1>
update_c = {"weight": np.array([5.0, 6.0])}
masked_c = aggregator.apply_masks("C", update_c, round_num=1)

<h1>èšåˆï¼ˆæ©ç¢¼ç›¸äº’æŠµæ¶ˆï¼‰</h1>
aggregated = aggregator.aggregate([masked_a, masked_b, masked_c])
print("Aggregated:", aggregated["weight"])
<h1>æ‡‰è©²æ¥è¿‘ [(1+3+5)/3, (2+4+6)/3] = [3.0, 4.0]</h1>
</code></pre>

<h3>5.3 é›¶çŸ¥è­˜è­‰æ˜ï¼ˆZero-Knowledge Proofsï¼‰</h3>

<strong>æ‡‰ç”¨å ´æ™¯ï¼š</strong>
- è­‰æ˜æœ¬åœ°æ•¸æ“šç¬¦åˆè¦æ±‚ï¼ˆä¸æ³„éœ²æ•¸æ“šï¼‰
- è­‰æ˜æ¨¡å‹è¨“ç·´éç¨‹æ­£ç¢º
- è­‰æ˜èšåˆçµæœå¯ä¿¡

<strong>ç°¡åŒ–ç¤ºä¾‹ï¼š</strong>
<pre><code><h1>å½ä»£ç¢¼ï¼šä½¿ç”¨zkSNARKè­‰æ˜æ•¸æ“šè³ªé‡</h1>
from py_ecc.bn128 import G1, G2, pairing

<p>class ZKQualityProof:
    def generate_proof(self, data, requirements):
        """
        ç”Ÿæˆæ•¸æ“šè³ªé‡è­‰æ˜
        """
        # 1. è¨ˆç®—æ•¸æ“šçµ±è¨ˆé‡
        stats = self._compute_stats(data)</p>

<p>        # 2. ç”Ÿæˆè­‰æ˜ï¼ˆæ»¿è¶³requirementsï¼‰
        proof = {
            'stats_hash': self._hash(stats),
            'satisfaction_proof': self._zk_proof(stats, requirements)
        }
        return proof</p>

<p>    def verify_proof(self, proof, requirements):
        """
        é©—è­‰è­‰æ˜ï¼ˆä¸æŸ¥çœ‹å¯¦éš›æ•¸æ“šï¼‰
        """
        # æª¢æŸ¥è­‰æ˜æ˜¯å¦æœ‰æ•ˆ
        return self._verify_zk_proof(
            proof['satisfaction_proof'],
            requirements
        )</p>

<p>    def _compute_stats(self, data):
        # è¨ˆç®—å¿…è¦çš„çµ±è¨ˆé‡
        return {
            'mean': np.mean(data),
            'std': np.std(data),
            'size': len(data)
        }</p>

<p>    def _hash(self, stats):
        # å“ˆå¸Œçµ±è¨ˆé‡
        stats_str = str(sorted(stats.items()))
        return hashlib.sha256(stats_str.encode()).hexdigest()</p>

<p>    def _zk_proof(self, stats, requirements):
        # å¯¦éš›æ‡‰ç”¨ä½¿ç”¨zkSNARKåº«å¦‚libsnark, bellmanç­‰
        # é€™è£¡æ˜¯ç°¡åŒ–ç¤ºæ„
        proof = {}
        for req, value in requirements.items():
            # ç”Ÿæˆã€Œstats[req] >= valueã€çš„é›¶çŸ¥è­˜è­‰æ˜
            proof[req] = f"proof_{stats[req]}_gte_{value}"
        return proof
</code></pre></p>

<h3>5.4 å·®åˆ†éš±ç§ï¼ˆDifferential Privacyï¼‰</h3>

<strong>é‡‘èæ•¸æ“šç‰¹é»ï¼š</strong>
- æ™‚åºæ•¸æ“šéœ€è¦è€ƒæ…®æ™‚åºç›¸é—œæ€§
- å¸‚å ´æ•æ„Ÿæ•¸æ“šéœ€è¦æ›´å¼·çš„éš±ç§é ç®—
- äº¤æ˜“æ•¸æ“šç¨€ç–æ€§é«˜

<strong>æ™‚åºæ•¸æ“šçš„å·®åˆ†éš±ç§ï¼š</strong>
<pre><code>import numpy as np

<p>class TimeSeriesDP:
    def __init__(self, epsilon=1.0, delta=1e-5):
        self.epsilon = epsilon
        self.delta = delta</p>

<p>    def add_noise_to_timeseries(self, ts, sensitivity=1.0):
        """
        ç‚ºæ™‚åºæ•¸æ“šæ·»åŠ å·®åˆ†éš±ç§å™ªè²
        ä½¿ç”¨æ™‚åºç›¸é—œçš„å™ªè²ä»¥ä¿ç•™æ™‚é–“æ¨¡å¼
        """
        n = len(ts)</p>

<p>        # è¨ˆç®—å™ªè²å°ºåº¦
        sigma = sensitivity <em> np.sqrt(2 </em> np.log(1.25 / self.delta)) / self.epsilon</p>

<p>        # ç”Ÿæˆç›¸é—œå™ªè²ï¼ˆé«˜æ–¯éç¨‹ï¼‰
        noise = np.random.normal(0, sigma, n)</p>

<p>        # å¹³æ»‘å™ªè²ï¼ˆä¿ç•™æ™‚é–“ç›¸é—œæ€§ï¼‰
        window = min(7, n)
        noise_smooth = np.convolve(noise, np.ones(window)/window, mode='same')</p>

<p>        return ts + noise_smooth</p>

<p>    def dp_moving_average(self, ts, window=5):
        """
        å·®åˆ†éš±ç§ç§»å‹•å¹³å‡
        """
        ma = np.convolve(ts, np.ones(window)/window, mode='valid')
        # ç‚ºçµæœæ·»åŠ å™ªè²
        dp_ma = self.add_noise_to_timeseries(ma, sensitivity=1/window)
        return dp_ma</p>

<h1>é‡‘èæ•¸æ“šæ‡‰ç”¨ç¤ºä¾‹</h1>
ts_dp = TimeSeriesDP(epsilon=0.5)  # è¼ƒåš´æ ¼çš„éš±ç§é ç®—

<h1>åŸå§‹åƒ¹æ ¼æ•¸æ“š</h1>
prices = np.array([100, 102, 101, 103, 105, 107, 106, 108])

<h1>æ·»åŠ å·®åˆ†éš±ç§å™ªè²</h1>
dp_prices = ts_dp.add_noise_to_timeseries(prices)
print("Original:", prices)
print("DP prices:", dp_prices)

<h1>å·®åˆ†éš±ç§ç§»å‹•å¹³å‡</h1>
dp_ma = ts_dp.dp_moving_average(prices, window=3)
print("DP MA:", dp_ma)
</code></pre>

<p>---</p>

<h2>å…­ã€å¯¦æ–½å»ºè­°</h2>

<h3>6.1 é …ç›®è¦åŠƒéšæ®µ</h3>

<strong>1. éœ€æ±‚è©•ä¼°</strong>
<pre><code>è©•ä¼°æ¸…å–®ï¼š
- åƒèˆ‡æ©Ÿæ§‹æ•¸é‡å’Œè¦æ¨¡
- æ•¸æ“šæ•æ„Ÿç­‰ç´šï¼ˆç›£ç®¡è¦æ±‚ï¼‰
- æ¨¡å‹è¤‡é›œåº¦å’Œæ€§èƒ½è¦æ±‚
- é€šè¨ŠåŸºç¤è¨­æ–½æ¢ä»¶
- æŠ€è¡“åœ˜éšŠèƒ½åŠ›
</code></pre>

<strong>2. æ¡†æ¶é¸æ“‡æ±ºç­–æ¨¹</strong>
<pre><code>é–‹å§‹
  â”‚
  â”œâ”€ ä½¿ç”¨ TensorFlowï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ TensorFlow Federated
  â”‚   â””â”€ å¦ â†’ ç¹¼çºŒ
  â”‚
  â”œâ”€ éš±ç§æŠ€è¡“è¦æ±‚é«˜ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ PySyft
  â”‚   â””â”€ å¦ â†’ ç¹¼çºŒ
  â”‚
  â”œâ”€ éœ€è¦å¿«é€Ÿç”Ÿç”¢éƒ¨ç½²ï¼Ÿ
  â”‚   â”œâ”€ æ˜¯ â†’ Flower
  â”‚   â””â”€ å¦ â†’ æ¡†æ¶å°æ¯”æ¸¬è©¦
</code></pre>

<h3>6.2 æŠ€è¡“æ¶æ§‹è¨­è¨ˆ</h3>

<strong>æ¨è–¦æ¶æ§‹ï¼š</strong>
<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç›£æ§å±¤                            â”‚
â”‚  - æ€§èƒ½ç›£æ§  - ç•°å¸¸æª¢æ¸¬  - å¯©è¨ˆæ—¥èªŒ                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      å”èª¿å±¤                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  ä»»å‹™èª¿åº¦å™¨  â”‚  â”‚  ç­–ç•¥å¼•æ“   â”‚  â”‚  å¯†é‘°ç®¡ç†   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      èšåˆå±¤                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ å®‰å…¨èšåˆæ¨¡å¡Š â”‚  â”‚ ç•°å¸¸æª¢æ¸¬æ¨¡å¡Š â”‚  â”‚ æ¨¡å‹ç‰ˆæœ¬åº« â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     é€šä¿¡å±¤                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  TLSåŠ å¯†   â”‚  â”‚ æ¶ˆæ¯éšŠåˆ—    â”‚  â”‚  å£“ç¸®/è§£å£“  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â–²
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     å®¢æˆ¶ç«¯ A      â”‚     å®¢æˆ¶ç«¯ B      â”‚     å®¢æˆ¶ç«¯ C     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æœ¬åœ°æ•¸æ“šåº«  â”‚ â”‚  â”‚ æœ¬åœ°æ•¸æ“šåº«  â”‚ â”‚  â”‚ æœ¬åœ°æ•¸æ“šåº«  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ æœ¬åœ°æ¨¡å‹    â”‚ â”‚  â”‚ æœ¬åœ°æ¨¡å‹    â”‚ â”‚  â”‚ æœ¬åœ°æ¨¡å‹    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ FLå®¢æˆ¶ç«¯ä»£ç† â”‚ â”‚  â”‚ FLå®¢æˆ¶ç«¯ä»£ç† â”‚ â”‚  â”‚ FLå®¢æˆ¶ç«¯ä»£ç† â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre>

<h3>6.3 åˆ†éšæ®µå¯¦æ–½è·¯ç·šåœ–</h3>

<strong>éšæ®µ1ï¼šæ¦‚å¿µé©—è­‰ï¼ˆ1-2å€‹æœˆï¼‰</strong>
<pre><code>ç›®æ¨™ï¼šé©—è­‰æŠ€è¡“å¯è¡Œæ€§
- å–®æ©Ÿæ¨¡æ“¬è¯é‚¦å­¸ç¿’
- åŸºæœ¬æ¨¡å‹è¨“ç·´æµç¨‹
- åŸºæœ¬é€šä¿¡æ©Ÿæ§‹
- ç°¡å–®èšåˆç®—æ³•

<p>äº¤ä»˜ç‰©ï¼š
- æ¦‚å¿µé©—è­‰å ±å‘Š
- åŸºç¤ä»£ç¢¼åº«
- æ€§èƒ½åŸºæº–æ¸¬è©¦
</code></pre></p>

<strong>éšæ®µ2ï¼šåŸå‹é–‹ç™¼ï¼ˆ2-3å€‹æœˆï¼‰</strong>
<pre><code>ç›®æ¨™ï¼šå¤šæ©Ÿæ§‹å”ä½œæ¼”ç¤º
- å¯¦éš›å¤šæ©Ÿæ§‹éƒ¨ç½²
- å®‰å…¨èšåˆå¯¦ç¾
- åŸºæœ¬éš±ç§ä¿è­·
- ç•°å¸¸æª¢æ¸¬æ©Ÿåˆ¶

<p>äº¤ä»˜ç‰©ï¼š
- å¯é‹è¡Œçš„åŸå‹ç³»çµ±
- æŠ€è¡“æ–‡æª”
- å®‰å…¨è©•ä¼°å ±å‘Š
</code></pre></p>

<strong>éšæ®µ3ï¼šç”Ÿç”¢æº–å‚™ï¼ˆ3-6å€‹æœˆï¼‰</strong>
<pre><code>ç›®æ¨™ï¼šç”Ÿç”¢ç´šç³»çµ±
- é«˜å¯ç”¨æ€§æ¶æ§‹
- å®Œæ•´ç›£æ§å’Œæ—¥èªŒ
- æ€§èƒ½å„ªåŒ–
- åˆè¦å¯©è¨ˆ

<p>äº¤ä»˜ç‰©ï¼š
- ç”Ÿç”¢å°±ç·’ç³»çµ±
- é‹ç¶­æ‰‹å†Š
- åˆè¦è­‰æ˜
</code></pre></p>

<h3>6.4 é¢¨éšªç·©è§£ç­–ç•¥</h3>

<table>
<tr> æ¨¡å‹æ€§èƒ½ä¸‹é™ <td>å¢åŠ æœ¬åœ°è¨“ç·´è¼ªæ•¸ï¼Œä½¿ç”¨çŸ¥è­˜è’¸é¤¾</td> æŠ€è¡“åœ˜éšŠ <td>æŒçºŒ</td>
<td>é€šä¿¡ç“¶é ¸</td> å¯¦æ–½æ¨¡å‹å£“ç¸®ï¼Œç•°æ­¥èšåˆ <td>æŠ€è¡“åœ˜éšŠ</td> éšæ®µ2 |
<td>æ•¸æ“šæ´©éœ²</td> å¤šå±¤åŠ å¯†ï¼Œå·®åˆ†éš±ç§ï¼Œå®‰å…¨å¯©è¨ˆ <td>å®‰å…¨åœ˜éšŠ</td> æŒçºŒ |
<td>æƒ¡æ„æ”»æ“Š</td> å®¢æˆ¶ç«¯èªè­‰ï¼Œç•°å¸¸æª¢æ¸¬ï¼ŒKrumèšåˆ <td>å®‰å…¨åœ˜éšŠ</td> éšæ®µ2 |
<td>åˆè¦å•é¡Œ</td> æ³•å‹™å¯©æŸ¥ï¼Œéš±ç§å½±éŸ¿è©•ä¼° <td>æ³•å‹™åœ˜éšŠ</td> éšæ®µ1 |
<td>æ©Ÿæ§‹é€€å‡º</td> æ¨¡å‹ç‰ˆæœ¬æ§åˆ¶ï¼Œå†·å»é€€å‡ºæ©Ÿåˆ¶ <td>é‹ç¶­åœ˜éšŠ</td> éšæ®µ3 |

<h3>6.5 ç›£æ§å’Œè©•ä¼°æŒ‡æ¨™</h3>

<strong>æŠ€è¡“æŒ‡æ¨™ï¼š</strong>
<pre><code>class FLPerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'round': [],
            'accuracy': [],
            'loss': [],
            'communication_cost': [],
            'training_time': [],
            'client_participation': [],
            'privacy_budget_used': [],
        }

<p>    def log_round(self, round_num, metrics):
        self.metrics['round'].append(round_num)
        self.metrics['accuracy'].append(metrics['accuracy'])
        self.metrics['loss'].append(metrics['loss'])
        self.metrics['communication_cost'].append(metrics['comm_cost'])
        self.metrics['training_time'].append(metrics['time'])
        self.metrics['client_participation'].append(metrics['num_clients'])
        self.metrics['privacy_budget_used'].append(metrics['epsilon'])</p>

<p>    def evaluate(self):
        """
        è©•ä¼°è¯é‚¦å­¸ç¿’æ€§èƒ½
        """
        # æ”¶æ–‚é€Ÿåº¦ï¼šé”åˆ°ç›®æ¨™æº–ç¢ºç‡æ‰€éœ€è¼ªæ•¸
        target_acc = 0.85
        convergence_round = None
        for i, acc in enumerate(self.metrics['accuracy']):
            if acc >= target_acc:
                convergence_round = self.metrics['round'][i]
                break</p>

<p>        # ç¸½é€šä¿¡æˆæœ¬
        total_comm = sum(self.metrics['communication_cost'])</p>

<p>        # ç¸½è¨“ç·´æ™‚é–“
        total_time = sum(self.metrics['training_time'])</p>

<p>        # å¹³å‡å®¢æˆ¶ç«¯åƒèˆ‡åº¦
        avg_participation = np.mean(self.metrics['client_participation'])</p>

<p>        # éš±ç§é ç®—ä½¿ç”¨
        total_epsilon = sum(self.metrics['privacy_budget_used'])</p>

<p>        return {
            'convergence_round': convergence_round,
            'total_communication': total_comm,
            'total_time': total_time,
            'avg_participation': avg_participation,
            'total_privacy_budget': total_epsilon,
        }</p>

<h1>ä½¿ç”¨ç¤ºä¾‹</h1>
monitor = FLPerformanceMonitor()

<h1>è¨“ç·´éç¨‹ä¸­è¨˜éŒ„</h1>
monitor.log_round(
    round_num=1,
    metrics={
        'accuracy': 0.75,
        'loss': 0.5,
        'comm_cost': 100.5,  # MB
        'time': 120.0,  # ç§’
        'num_clients': 8,
        'epsilon': 0.1
    }
)

<h1>è©•ä¼°</h1>
evaluation = monitor.evaluate()
print("Evaluation:", evaluation)
</code></pre>

<strong>æ¥­å‹™æŒ‡æ¨™ï¼š</strong>
- æ¨¡å‹é æ¸¬æº–ç¢ºç‡æå‡
- ç­–ç•¥å›å ±ç‡æ”¹å–„
- é¢¨éšªæŒ‡æ¨™å„ªåŒ–
- åˆè¦æª¢æŸ¥é€šéç‡

<p>---</p>

<h2>ä¸ƒã€ä»£ç¢¼ç¤ºä¾‹</h2>

<h3>7.1 å®Œæ•´çš„è¯é‚¦å­¸ç¿’ç¤ºä¾‹ï¼ˆFloweræ¡†æ¶ï¼‰</h3>

<strong>æœå‹™å™¨ç«¯ï¼ˆserver.pyï¼‰ï¼š</strong>
<pre><code><h1>server.py</h1>
import flwr as fl
import numpy as np
from typing import List, Tuple, Dict
import logging

<h1>é…ç½®æ—¥èªŒ</h1>
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

<h1>å®šç¾©è‡ªå®šç¾©èšåˆç­–ç•¥</h1>
class FedAvgWithAdaptiveWeights(fl.server.strategy.FedAvg):
    def __init__(self, min_fit_clients=3, min_available_clients=3, **kwargs):
        super().__init__(
            min_fit_clients=min_fit_clients,
            min_available_clients=min_available_clients,
            **kwargs
        )
        self.client_scores = {}  # è¨˜éŒ„å®¢æˆ¶ç«¯æ­·å²è¡¨ç¾

<p>    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[fl.client.ClientProxy, fl.common.FitRes]],
        failures: List[Union[Tuple[fl.client.ClientProxy, FitRes], BaseException]],
    ) -> Tuple[Optional[bytes], Dict[str, Scalar]]:
        """è‡ªé©æ‡‰æ¬Šé‡èšåˆ"""
        if not results:
            return None, {}</p>

<p>        # èšåˆåƒæ•¸
        aggregated_parameters, aggregated_metrics = super().aggregate_fit(
            server_round, results, failures
        )</p>

<p>        # æ›´æ–°å®¢æˆ¶ç«¯è¡¨ç¾åˆ†æ•¸
        for client_proxy, fit_res in results:
            client_id = client_proxy.cid
            metrics = fit_res.metrics</p>

<p>            if 'val_accuracy' in metrics:
                accuracy = metrics['val_accuracy']
                self.client_scores[client_id] = accuracy
                logger.info(f"Client {client_id} accuracy: {accuracy:.4f}")</p>

<p>        # è¨˜éŒ„èšåˆæŒ‡æ¨™
        aggregated_metrics['client_count'] = len(results)
        aggregated_metrics['server_round'] = server_round</p>

<p>        return aggregated_parameters, aggregated_metrics</p>

<p>    def configure_fit(
        self, server_round: int, parameters: List[np.ndarray], client_manager: ClientManager
    ) -> List[Tuple[ClientProxy, FitIns]]:
        """é…ç½®å®¢æˆ¶ç«¯æœ¬åœ°è¨“ç·´åƒæ•¸"""
        config = {
            'server_round': server_round,
            'local_epochs': 5,
            'batch_size': 32,
            'learning_rate': 0.01 <em> (0.99 </em>* server_round),  # è¡°æ¸›å­¸ç¿’ç‡
        }</p>

<p>        # é¸æ“‡å®¢æˆ¶ç«¯
        clients = client_manager.sample(
            num_clients=self.min_fit_clients,
            min_num_clients=self.min_available_clients
        )</p>

<p>        # å‰µå»ºé…ç½®
        fit_ins = fl.common.FitIns(
            parameters=parameters,
            config=config
        )</p>

<p>        return [(client, fit_ins) for client in clients]</p>

<h1>å•Ÿå‹•æœå‹™å™¨</h1>
def start_server():
    logger.info("Starting Federated Learning Server...")

<p>    # å‰µå»ºç­–ç•¥
    strategy = FedAvgWithAdaptiveWeights(
        min_fit_clients=3,
        min_available_clients=5,
        fraction_fit=0.6,
        fraction_evaluate=0.6,
    )</p>

<p>    # å•Ÿå‹•æœå‹™å™¨
    fl.server.start_server(
        server_address="0.0.0.0:8080",
        config=fl.server.ServerConfig(num_rounds=20),
        strategy=strategy,
    )</p>

<p>if __name__ == "__main__":
    start_server()
</code></pre></p>

<strong>å®¢æˆ¶ç«¯ï¼ˆclient.pyï¼‰ï¼š</strong>
<pre><code><h1>client.py</h1>
import flwr as fl
import numpy as np
from typing import Dict, List, Tuple
import logging

<p>logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)</p>

<h1>æ¨¡æ“¬é‡åŒ–ç ”ç©¶æ¨¡å‹</h1>
class QuantResearchModel:
    def __init__(self, input_dim=10, hidden_dim=32):
        # ç°¡åŒ–çš„ç¥ç¶“ç¶²çµ¡
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim

<p>        # åˆå§‹åŒ–åƒæ•¸
        np.random.seed(42)
        self.W1 = np.random.randn(input_dim, hidden_dim) * 0.1
        self.b1 = np.zeros(hidden_dim)
        self.W2 = np.random.randn(hidden_dim, 1) * 0.1
        self.b2 = np.zeros(1)</p>

<p>    def forward(self, X):
        """å‰å‘å‚³æ’­"""
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = np.tanh(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.z2  # å›æ­¸ä»»å‹™
        return self.a2</p>

<p>    def backward(self, X, y, learning_rate=0.01):
        """åå‘å‚³æ’­"""
        m = X.shape[0]</p>

<p>        # è¼¸å‡ºå±¤æ¢¯åº¦
        dz2 = self.a2 - y.reshape(-1, 1)
        dW2 = np.dot(self.a1.T, dz2) / m
        db2 = np.sum(dz2, axis=0) / m</p>

<p>        # éš±è—å±¤æ¢¯åº¦
        da1 = np.dot(dz2, self.W2.T)
        dz1 = da1 <em> (1 - self.a1</em>*2)
        dW1 = np.dot(X.T, dz1) / m
        db1 = np.sum(dz1, axis=0) / m</p>

<p>        # æ›´æ–°åƒæ•¸
        self.W2 -= learning_rate * dW2
        self.b2 -= learning_rate * db2
        self.W1 -= learning_rate * dW1
        self.b1 -= learning_rate * db1</p>

<p>        # è¿”å›åƒæ•¸æ›´æ–°
        updates = {
            'W1': dW1,
            'b1': db1,
            'W2': dW2,
            'b2': db2
        }
        return updates</p>

<p>    def get_weights(self) -> List[np.ndarray]:
        """ç²å–æ¨¡å‹æ¬Šé‡"""
        return [self.W1, self.b1, self.W2, self.b2]</p>

<p>    def set_weights(self, weights: List[np.ndarray]):
        """è¨­ç½®æ¨¡å‹æ¬Šé‡"""
        self.W1, self.b1, self.W2, self.b2 = weights</p>

<p>    def train(self, X, y, epochs=5, learning_rate=0.01):
        """æœ¬åœ°è¨“ç·´"""
        for epoch in range(epochs):
            # å‰å‘å‚³æ’­
            predictions = self.forward(X)</p>

<p>            # è¨ˆç®—æå¤±
            loss = np.mean((predictions - y.reshape(-1, 1))**2)</p>

<p>            # åå‘å‚³æ’­
            self.backward(X, y, learning_rate)</p>

<p>            if epoch % 10 == 0:
                logger.info(f"Epoch {epoch}, Loss: {loss:.4f}")</p>

<p>        return loss</p>

<p>    def evaluate(self, X, y) -> Tuple[float, float]:
        """è©•ä¼°æ¨¡å‹"""
        predictions = self.forward(X)
        mse = np.mean((predictions - y.reshape(-1, 1))**2)
        mae = np.mean(np.abs(predictions - y.reshape(-1, 1)))
        return mse, mae</p>

<h1>æ¨¡æ“¬æœ¬åœ°æ•¸æ“š</h1>
class LocalDataLoader:
    def __init__(self, client_id):
        self.client_id = client_id

<p>        # ç‚ºæ¯å€‹å®¢æˆ¶ç«¯ç”Ÿæˆä¸åŒçš„æ•¸æ“šåˆ†å¸ƒ
        np.random.seed(hash(client_id) % 2**32)</p>

<p>        n_samples = 1000
        input_dim = 10</p>

<p>        # ç”Ÿæˆç‰¹å¾µ
        self.X_train = np.random.randn(n_samples, input_dim)
        self.y_train = np.sum(self.X_train[:, :5], axis=1) + np.random.randn(n_samples) * 0.1</p>

<p>        self.X_val = np.random.randn(200, input_dim)
        self.y_val = np.sum(self.X_val[:, :5], axis=1) + np.random.randn(200) * 0.1</p>

<p>        logger.info(f"Client {client_id} data loaded: Train={n_samples}, Val=200")</p>

<p>    def get_batch(self, batch_size=32):
        """ç²å–æ‰¹æ¬¡æ•¸æ“š"""
        indices = np.random.permutation(len(self.X_train))[:batch_size]
        return self.X_train[indices], self.y_train[indices]</p>

<h1>è¯é‚¦å­¸ç¿’å®¢æˆ¶ç«¯</h1>
class QuantFlowerClient(fl.client.NumPyClient):
    def __init__(self, client_id: str):
        self.client_id = client_id
        self.model = QuantResearchModel()
        self.data_loader = LocalDataLoader(client_id)

<p>        # å·®åˆ†éš±ç§åƒæ•¸
        self.dp_enabled = True
        self.noise_multiplier = 0.5
        self.clip_norm = 1.0</p>

<p>    def get_parameters(self, config):
        """ç²å–æ¨¡å‹åƒæ•¸"""
        return self.model.get_weights()</p>

<p>    def fit(self, parameters, config):
        """æœ¬åœ°è¨“ç·´"""
        # è¨­ç½®å…¨å±€æ¨¡å‹åƒæ•¸
        self.model.set_weights(parameters)</p>

<p>        # è®€å–é…ç½®
        local_epochs = config.get('local_epochs', 5)
        batch_size = config.get('batch_size', 32)
        learning_rate = config.get('learning_rate', 0.01)</p>

<p>        # æœ¬åœ°è¨“ç·´
        total_loss = 0
        num_batches = 0</p>

<p>        for epoch in range(local_epochs):
            X_batch, y_batch = self.data_loader.get_batch(batch_size)
            loss = self.model.train(X_batch, y_batch, epochs=1, learning_rate=learning_rate)
            total_loss += loss
            num_batches += 1</p>

<p>        avg_loss = total_loss / num_batches</p>

<p>        # è©•ä¼°æœ¬åœ°æ¨¡å‹
        val_mse, val_mae = self.model.evaluate(
            self.data_loader.X_val,
            self.data_loader.y_val
        )</p>

<p>        # è¿”å›æ›´æ–°
        new_parameters = self.model.get_weights()</p>

<p>        metrics = {
            'loss': avg_loss,
            'val_mse': val_mse,
            'val_mae': val_mae,
            'val_accuracy': 1.0 - val_mae,  # è½‰æ›ç‚ºæº–ç¢ºç‡æŒ‡æ¨™
            'client_id': self.client_id
        }</p>

<p>        logger.info(
            f"Client {self.client_id} - Loss: {avg_loss:.4f}, "
            f"Val MSE: {val_mse:.4f}, Val MAE: {val_mae:.4f}"
        )</p>

<p>        return new_parameters, len(self.data_loader.X_train), metrics</p>

<p>    def evaluate(self, parameters, config):
        """è©•ä¼°å…¨å±€æ¨¡å‹"""
        self.model.set_weights(parameters)</p>

<p>        mse, mae = self.model.evaluate(
            self.data_loader.X_val,
            self.data_loader.y_val
        )</p>

<p>        return mse, len(self.data_loader.X_val), {
            'mse': mse,
            'mae': mae,
            'client_id': self.client_id
        }</p>

<h1>å•Ÿå‹•å®¢æˆ¶ç«¯</h1>
def start_client(client_id: str, server_address: str = "localhost:8080"):
    logger.info(f"Starting Federated Learning Client {client_id}...")

<p>    # å‰µå»ºå®¢æˆ¶ç«¯
    client = QuantFlowerClient(client_id)</p>

<p>    # å•Ÿå‹•é€£æ¥
    fl.client.start_numpy_client(
        server_address=server_address,
        client=client
    )</p>

<p>if __name__ == "__main__":
    import sys</p>

<p>    # å¾å‘½ä»¤è¡Œç²å–å®¢æˆ¶ç«¯ID
    client_id = sys.argv[1] if len(sys.argv) > 1 else "client_1"
    server_address = sys.argv[2] if len(sys.argv) > 2 else "localhost:8080"</p>

<p>    start_client(client_id, server_address)
</code></pre></p>

<strong>é‹è¡Œèªªæ˜ï¼š</strong>
<pre><code><h1>çµ‚ç«¯1ï¼šå•Ÿå‹•æœå‹™å™¨</h1>
python server.py

<h1>çµ‚ç«¯2-4ï¼šå•Ÿå‹•å¤šå€‹å®¢æˆ¶ç«¯</h1>
python client.py client_1
python client.py client_2
python client.py client_3
</code></pre>

<h3>7.2 å¸¶å®‰å…¨èšåˆçš„è¯é‚¦å­¸ç¿’</h3>

<pre><code><h1>secure_aggregation.py</h1>
import numpy as np
from typing import List, Dict
import hashlib
from cryptography.fernet import Fernet
import json

<p>class SecureAggregator:
    """
    å®‰å…¨èšåˆå¯¦ç¾ï¼Œä½¿ç”¨é…å°æ©ç¢¼æŠ€è¡“
    """</p>

<p>    def __init__(self, client_ids: List[str]):
        self.client_ids = client_ids
        self.pair_keys = self._generate_pairwise_keys()
        self.round_seeds = {}</p>

<p>    def _generate_pairwise_keys(self) -> Dict[tuple, bytes]:
        """
        ç‚ºæ¯å°å®¢æˆ¶ç«¯ç”Ÿæˆå…±äº«å¯†é‘°
        å¯¦éš›æ‡‰ç”¨ä¸­ä½¿ç”¨TLSæˆ–Diffie-Hellman
        """
        keys = {}
        n = len(self.client_ids)</p>

<p>        for i in range(n):
            for j in range(i+1, n):
                client_a = self.client_ids[i]
                client_b = self.client_ids[j]</p>

<p>                # ç”Ÿæˆå°ç¨±å¯†é‘°
                key = Fernet.generate_key()
                keys[(client_a, client_b)] = key
                keys[(client_b, client_a)] = key</p>

<p>        return keys</p>

<p>    def _get_key(self, client_a: str, client_b: str) -> bytes:
        """ç²å–å®¢æˆ¶ç«¯å°çš„å¯†é‘°"""
        return self.pair_keys.get((client_a, client_b), self.pair_keys.get((client_b, client_a)))</p>

<p>    def _generate_mask(
        self,
        key: bytes,
        shape: tuple,
        round_num: int,
        client_seed: int
    ) -> np.ndarray:
        """
        ä½¿ç”¨å¯†é‘°ç”Ÿæˆç¢ºå®šæ€§éš¨æ©Ÿæ©ç¢¼
        """
        # ä½¿ç”¨roundå’Œclientçµ„åˆç”Ÿæˆç¨®å­
        combined_seed = f"{round_num}_{client_seed}".encode()
        cipher = Fernet(key)</p>

<p>        # åŠ å¯†ç¨®å­
        encrypted = cipher.encrypt(combined_seed.ljust(16, b'\0'))</p>

<p>        # è½‰æ›ç‚ºéš¨æ©Ÿæ•¸
        hash_val = hashlib.sha256(encrypted).hexdigest()
        seed_int = int(hash_val[:16], 16)</p>

<p>        # ç”Ÿæˆæ©ç¢¼
        rng = np.random.RandomState(seed_int)
        mask = rng.randn(<em>shape) </em> 0.1  # æ¨™æº–å·®0.1</p>

<p>        return mask</p>

<p>    def add_mask(
        self,
        client_id: str,
        parameters: Dict[str, np.ndarray],
        round_num: int,
        client_seed: int = None
    ) -> Dict[str, np.ndarray]:
        """
        å®¢æˆ¶ç«¯æ·»åŠ æ©ç¢¼åˆ°åƒæ•¸
        """
        if client_seed is None:
            client_seed = hash(client_id) % 2**32</p>

<p>        masked_params = {}</p>

<p>        for name, param in parameters.items():
            mask = np.zeros_like(param)</p>

<p>            # å°æ¯å€‹å…¶ä»–å®¢æˆ¶ç«¯æ·»åŠ æ©ç¢¼
            for other_id in self.client_ids:
                if other_id == client_id:
                    continue</p>

<p>                # ç²å–å…±äº«å¯†é‘°
                key = self._get_key(client_id, other_id)</p>

<p>                # ç”Ÿæˆæ©ç¢¼
                other_seed = hash(other_id) % 2**32
                mask = mask + self._generate_mask(
                    key, param.shape, round_num, other_seed
                )</p>

<p>            # æ·»åŠ æ©ç¢¼
            masked_params[name] = param + mask</p>

<p>        return masked_params</p>

<p>    def aggregate(
        self,
        masked_updates: List[Dict[str, np.ndarray]]
    ) -> Dict[str, np.ndarray]:
        """
        æœå‹™å™¨èšåˆæ©ç¢¼æ›´æ–°
        æ©ç¢¼æ‡‰è©²ç›¸äº’æŠµæ¶ˆ
        """
        if not masked_updates:
            return {}</p>

<p>        n_clients = len(masked_updates)
        aggregated = {}</p>

<p>        # èšåˆæ¯å€‹åƒæ•¸
        for name in masked_updates[0].keys():
            # æ±‚å’Œ
            sum_param = sum(update[name] for update in masked_updates)</p>

<p>            # å¹³å‡
            aggregated[name] = sum_param / n_clients</p>

<p>        return aggregated</p>

<p>    def save_state(self, filepath: str):
        """ä¿å­˜èšåˆå™¨ç‹€æ…‹"""
        state = {
            'client_ids': self.client_ids,
            'round_seeds': self.round_seeds
            # æ³¨æ„ï¼špair_keysæ‡‰è©²å®‰å…¨å­˜å„²ï¼Œä¸å»ºè­°åºåˆ—åŒ–åˆ°æ–‡ä»¶
        }
        with open(filepath, 'w') as f:
            json.dump(state, f)</p>

<p>    def load_state(self, filepath: str):
        """åŠ è¼‰èšåˆå™¨ç‹€æ…‹"""
        with open(filepath, 'r') as f:
            state = json.load(f)
        self.round_seeds = state['round_seeds']</p>

<h1>ä½¿ç”¨ç¤ºä¾‹</h1>
def demo_secure_aggregation():
    """æ¼”ç¤ºå®‰å…¨èšåˆ"""
    print("=" * 60)
    print("Secure Aggregation Demo")
    print("=" * 60)

<p>    # æ¨¡æ“¬3å€‹å®¢æˆ¶ç«¯
    client_ids = ['client_A', 'client_B', 'client_C']
    aggregator = SecureAggregator(client_ids)</p>

<p>    # æ¨¡æ“¬æ¨¡å‹åƒæ•¸
    params_A = {'weight': np.array([1.0, 2.0, 3.0]), 'bias': np.array([0.5])}
    params_B = {'weight': np.array([4.0, 5.0, 6.0]), 'bias': np.array([1.5])}
    params_C = {'weight': np.array([7.0, 8.0, 9.0]), 'bias': np.array([2.5])}</p>

<p>    print("\nOriginal Parameters:")
    print(f"Client A: {params_A}")
    print(f"Client B: {params_B}")
    print(f"Client C: {params_C}")</p>

<p>    # è¨ˆç®—æœŸæœ›çš„èšåˆçµæœ
    expected = {}
    for name in params_A.keys():
        expected[name] = (params_A[name] + params_B[name] + params_C[name]) / 3</p>

<p>    print(f"\nExpected Aggregation (without masks):")
    print(expected)</p>

<p>    # å®¢æˆ¶ç«¯æ·»åŠ æ©ç¢¼
    print("\n" + "-" * 60)
    print("Adding masks...")</p>

<p>    round_num = 1
    masked_A = aggregator.add_mask('client_A', params_A, round_num)
    masked_B = aggregator.add_mask('client_B', params_B, round_num)
    masked_C = aggregator.add_mask('client_C', params_C, round_num)</p>

<p>    print(f"\nMasked Parameters:")
    print(f"Client A: {masked_A}")
    print(f"Client B: {masked_B}")
    print(f"Client C: {masked_C}")</p>

<p>    # èšåˆï¼ˆæ©ç¢¼æ‡‰è©²æŠµæ¶ˆï¼‰
    print("\n" + "-" * 60)
    print("Aggregating...")</p>

<p>    aggregated = aggregator.aggregate([masked_A, masked_B, masked_C])</p>

<p>    print(f"\nAggregated Result:")
    print(aggregated)</p>

<p>    # é©—è­‰
    print("\n" + "-" * 60)
    print("Verification:")
    for name in expected.keys():
        diff = np.abs(aggregated[name] - expected[name]).max()
        print(f"{name}: max difference = {diff:.10f}")
        if diff < 1e-10:
            print(f"  âœ“ Masks canceled successfully")
        else:
            print(f"  âœ— Masks did not cancel properly")</p>

<p>    print("\n" + "=" * 60)</p>

<p>if __name__ == "__main__":
    demo_secure_aggregation()
</code></pre></p>

<h3>7.3 å·®åˆ†éš±ç§è¯é‚¦å­¸ç¿’</h3>

<pre><code><h1>dp_federated_learning.py</h1>
import numpy as np
from typing import Dict, List, Tuple
import flwr as fl

<p>class DPFederatedClient(fl.client.NumPyClient):
    """
    å¸¶å·®åˆ†éš±ç§çš„è¯é‚¦å­¸ç¿’å®¢æˆ¶ç«¯
    """</p>

<p>    def __init__(
        self,
        model,
        train_data,
        val_data,
        client_id: str,
        enable_dp: bool = True,
        epsilon: float = 0.5,
        delta: float = 1e-5,
        clip_norm: float = 1.0
    ):
        self.model = model
        self.train_data = train_data
        self.val_data = val_data
        self.client_id = client_id
        self.enable_dp = enable_dp
        self.epsilon = epsilon
        self.delta = delta
        self.clip_norm = clip_norm</p>

<p>        # è¨ˆç®—DPå™ªè²å°ºåº¦
        self.noise_scale = self._compute_noise_scale()</p>

<p>    def _compute_noise_scale(self) -> float:
        """è¨ˆç®—å·®åˆ†éš±ç§å™ªè²å°ºåº¦"""
        sensitivity = self.clip_norm  # æ¢¯åº¦è£å‰ªå¾Œçš„æ•æ„Ÿåº¦
        noise_scale = sensitivity <em> np.sqrt(2 </em> np.log(1.25 / self.delta)) / self.epsilon
        return noise_scale</p>

<p>    def _clip_gradients(self, gradients: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """æ¢¯åº¦è£å‰ª"""
        clipped = {}
        for name, grad in gradients.items():
            grad_norm = np.linalg.norm(grad)
            if grad_norm > self.clip_norm:
                grad = grad * (self.clip_norm / grad_norm)
            clipped[name] = grad
        return clipped</p>

<p>    def _add_noise(self, parameters: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """æ·»åŠ å·®åˆ†éš±ç§å™ªè²"""
        noisy_params = {}
        for name, param in parameters.items():
            noise = np.random.normal(0, self.noise_scale, param.shape)
            noisy_params[name] = param + noise
        return noisy_params</p>

<p>    def get_parameters(self, config):
        """ç²å–æ¨¡å‹åƒæ•¸"""
        return self.model.get_weights()</p>

<p>    def fit(self, parameters, config):
        """æœ¬åœ°è¨“ç·´"""
        # è¨­ç½®å…¨å±€æ¨¡å‹
        self.model.set_weights(parameters)</p>

<p>        # æœ¬åœ°è¨“ç·´
        local_epochs = config.get('local_epochs', 5)
        loss = self._local_train(local_epochs)</p>

<p>        # ç²å–æ›´æ–°
        global_params = parameters
        local_params = self.model.get_weights()</p>

<p>        # è¨ˆç®—æ¢¯åº¦ï¼ˆæ›´æ–°ï¼‰
        gradients = {}
        for i in range(len(global_params)):
            gradients[f'param_{i}'] = local_params[i] - global_params[i]</p>

<p>        # æ‡‰ç”¨å·®åˆ†éš±ç§
        if self.enable_dp:
            # æ¢¯åº¦è£å‰ª
            clipped_gradients = self._clip_gradients(gradients)</p>

<p>            # æ·»åŠ å™ªè²
            noisy_gradients = self._add_noise(clipped_gradients)</p>

<p>            # è½‰æ›å›åƒæ•¸æ›´æ–°
            noisy_updates = []
            for i in range(len(global_params)):
                noisy_updates.append(global_params[i] + noisy_gradients[f'param_{i}'])</p>

<p>            new_params = noisy_updates
        else:
            new_params = local_params</p>

<p>        # è©•ä¼°
        val_loss = self._evaluate()</p>

<p>        metrics = {
            'loss': loss,
            'val_loss': val_loss,
            'client_id': self.client_id,
            'dp_enabled': self.enable_dp,
            'epsilon': self.epsilon,
            'clip_norm': self.clip_norm
        }</p>

<p>        return new_params, len(self.train_data[0]), metrics</p>

<p>    def _local_train(self, epochs: int) -> float:
        """æœ¬åœ°è¨“ç·´ï¼ˆå¯¦éš›å¯¦ç¾å–æ±ºæ–¼æ¨¡å‹ï¼‰"""
        # é€™è£¡æ‡‰è©²æ˜¯å…·é«”çš„è¨“ç·´é‚è¼¯
        # è¿”å›è¨“ç·´æå¤±
        return 0.5  # ç¤ºä¾‹å€¼</p>

<p>    def _evaluate(self) -> float:
        """è©•ä¼°æ¨¡å‹"""
        # é€™è£¡æ‡‰è©²æ˜¯å…·é«”çš„è©•ä¼°é‚è¼¯
        # è¿”å›é©—è­‰æå¤±
        return 0.45  # ç¤ºä¾‹å€¼</p>

<p>class DPAggregationStrategy(fl.server.strategy.FedAvg):
    """
    å·®åˆ†éš±ç§èšåˆç­–ç•¥
    è·Ÿè¹¤ç´¯ç©çš„éš±ç§é ç®—
    """</p>

<p>    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.total_epsilon = 0.0
        self.rounds_trained = 0</p>

<p>    def aggregate_fit(
        self,
        server_round: int,
        results: List[Tuple[fl.client.ClientProxy, fl.common.FitRes]],
        failures: List,
    ):
        """èšåˆä¸¦è·Ÿè¹¤éš±ç§é ç®—"""
        # èšåˆåƒæ•¸
        aggregated_parameters, metrics = super().aggregate_fit(
            server_round, results, failures
        )</p>

<p>        # ç´¯ç©éš±ç§é ç®—
        round_epsilon = 0.0
        num_dp_clients = 0</p>

<p>        for client_proxy, fit_res in results:
            client_metrics = fit_res.metrics
            if client_metrics.get('dp_enabled', False):
                round_epsilon += client_metrics.get('epsilon', 0.0)
                num_dp_clients += 1</p>

<p>        # ä½¿ç”¨çµ„åˆå®šç†ä¼°è¨ˆç¸½éš±ç§æå¤±
        if num_dp_clients > 0:
            # ç°¡å–®ç´¯ç©ï¼ˆå¯¦éš›æ‡‰ç”¨ä½¿ç”¨æ›´ç²¾ç¢ºçš„çµ„åˆå®šç†ï¼‰
            self.total_epsilon += round_epsilon / num_dp_clients</p>

<p>        self.rounds_trained += 1</p>

<p>        # æ·»åŠ åˆ°æŒ‡æ¨™
        metrics['total_epsilon'] = self.total_epsilon
        metrics['rounds_trained'] = self.rounds_trained
        metrics['dp_clients'] = num_dp_clients</p>

<p>        print(f"\n=== Round {server_round} ===")
        print(f"DP Clients: {num_dp_clients}")
        print(f"Round Îµ: {round_epsilon:.4f}")
        print(f"Total Îµ: {self.total_epsilon:.4f}")</p>

<p>        # æª¢æŸ¥éš±ç§é ç®—
        if self.total_epsilon > 10.0:
            print("WARNING: Privacy budget nearly exhausted!")</p>

<p>        return aggregated_parameters, metrics</p>

<p>def demo_dp_federated_learning():
    """æ¼”ç¤ºå·®åˆ†éš±ç§è¯é‚¦å­¸ç¿’"""
    print("=" * 60)
    print("Differential Privacy Federated Learning Demo")
    print("=" * 60)</p>

<p>    # å‰µå»ºå¸¶DPçš„èšåˆç­–ç•¥
    strategy = DPAggregationStrategy(
        min_fit_clients=2,
        min_available_clients=2
    )</p>

<p>    # æ¨¡æ“¬å®¢æˆ¶ç«¯æ›´æ–°
    updates = [
        {'param_0': np.array([1.0, 2.0]), 'param_1': np.array([0.5])},
        {'param_0': np.array([3.0, 4.0]), 'param_1': np.array([1.5])},
    ]</p>

<p>    # è¨ˆç®—åŸå§‹èšåˆ
    original_agg = {}
    for name in updates[0].keys():
        original_agg[name] = sum(u[name] for u in updates) / len(updates)</p>

<p>    print("\nOriginal Updates:")
    for i, update in enumerate(updates):
        print(f"  Client {i+1}: {update}")</p>

<p>    print(f"\nOriginal Aggregation:")
    print(f"  {original_agg}")</p>

<p>    # å‰µå»ºDPå®¢æˆ¶ç«¯
    model = None  # å¯¦éš›æ‡‰ç”¨ä¸­ä½¿ç”¨çœŸå¯¦æ¨¡å‹
    dp_client = DPFederatedClient(
        model=model,
        train_data=(None, None),
        val_data=(None, None),
        client_id="demo_client",
        enable_dp=True,
        epsilon=0.5,
        delta=1e-5,
        clip_norm=1.0
    )</p>

<p>    print("\n" + "-" * 60)
    print("Applying Differential Privacy...")</p>

<p>    # æ‡‰ç”¨DP
    noisy_updates = []
    for update in updates:
        clipped = dp_client._clip_gradients(update)
        noisy = dp_client._add_noise(clipped)
        noisy_updates.append(noisy)</p>

<p>    print("\nNoisy Updates:")
    for i, update in enumerate(noisy_updates):
        print(f"  Client {i+1}: {update}")</p>

<p>    # èšåˆ
    noisy_agg = {}
    for name in noisy_updates[0].keys():
        noisy_agg[name] = sum(u[name] for u in noisy_updates) / len(noisy_updates)</p>

<p>    print(f"\nNoisy Aggregation:")
    print(f"  {noisy_agg}")</p>

<p>    # æ¯”è¼ƒ
    print("\n" + "-" * 60)
    print("Comparison:")
    for name in original_agg.keys():
        diff = np.abs(noisy_agg[name] - original_agg[name])
        print(f"{name}:")
        print(f"  Original: {original_agg[name]}")
        print(f"  DP:       {noisy_agg[name]}")
        print(f"  Diff:     {diff}")</p>

<p>    print("\n" + "=" * 60)</p>

<p>if __name__ == "__main__":
    demo_dp_federated_learning()
</code></pre></p>

<p>---</p>

<h2>å…«ã€ç¸½çµèˆ‡å±•æœ›</h2>

<h3>8.1 æ ¸å¿ƒçµè«–</h3>

<p>1. <strong>è¯é‚¦å­¸ç¿’åœ¨é‡åŒ–ç ”ç©¶ä¸­çš„åƒ¹å€¼å·²é©—è­‰</strong>
   - éš±ç§ä¿è­·å‰æä¸‹å¯¦ç¾æ•¸æ“šå”ä½œ
   - èƒ½å¤ é¡¯è‘—æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
   - ç¬¦åˆé‡‘èç›£ç®¡åˆè¦è¦æ±‚</p>

<p>2. <strong>æŠ€è¡“æˆç†Ÿåº¦è¶³ä»¥æ”¯æŒç”Ÿç”¢éƒ¨ç½²</strong>
   - å¤šå€‹é–‹æºæ¡†æ¶å¯é¸
   - å®‰å…¨èšåˆæŠ€è¡“æˆç†Ÿ
   - æ€§èƒ½å„ªåŒ–æ–¹æ¡ˆå®Œå‚™</p>

<p>3. <strong>ä¸»è¦æŒ‘æˆ°å¯æ§</strong>
   - é€šä¿¡æˆæœ¬å¯é€šéå£“ç¸®å’Œç•°æ­¥ç·©è§£
   - æ•¸æ“šç•°æ§‹æœ‰æˆç†Ÿçš„è§£æ±ºæ–¹æ¡ˆ
   - å®‰å…¨æ€§å¯é€šéå¤šå±¤é˜²è­·ä¿éšœ</p>

<h3>8.2 æœªä¾†ç™¼å±•æ–¹å‘</h3>

<p>1. <strong>æŠ€è¡“è¶¨å‹¢</strong>
   - è‡ªå‹•åŒ–è¯é‚¦å­¸ç¿’å¹³å°
   - å€å¡Šéˆå¢å¼·çš„å¯ä¿¡èšåˆ
   - è¯é‚¦å¢å¼·å­¸ç¿’</p>

<p>2. <strong>æ‡‰ç”¨æ‹“å±•</strong>
   - è·¨è³‡ç”¢é¡åˆ¥è¯åˆå»ºæ¨¡
   - å¯¦æ™‚é¢¨éšªè¯å‹•ç›£æ§
   - è¯é‚¦åæ´—éŒ¢ç³»çµ±</p>

<p>3. <strong>æ¨™æº–åŒ–</strong>
   - è¯é‚¦å­¸ç¿’äº’æ“ä½œæ€§æ¨™æº–
   - éš±ç§è¨ˆç®—èªè­‰æ¡†æ¶
   - è¡Œæ¥­æœ€ä½³å¯¦è¸æŒ‡å—</p>

<h3>8.3 è¡Œå‹•å»ºè­°</h3>

<p>å°æ–¼é‡åŒ–ç ”ç©¶æ©Ÿæ§‹ï¼š</p>

<p>1. <strong>çŸ­æœŸï¼ˆ3-6å€‹æœˆï¼‰ï¼šå•Ÿå‹•æ¦‚å¿µé©—è­‰</strong>
   - é¸æ“‡å°è¦æ¨¡åˆä½œå¤¥ä¼´
   - é©—è­‰æ ¸å¿ƒæŠ€è¡“å¯è¡Œæ€§
   - è©•ä¼°å•†æ¥­åƒ¹å€¼</p>

<p>2. <strong>ä¸­æœŸï¼ˆ6-12å€‹æœˆï¼‰ï¼šæ§‹å»ºç”Ÿç”¢ç³»çµ±</strong>
   - æ“´å¤§åƒèˆ‡æ©Ÿæ§‹ç¯„åœ
   - å®Œå–„å®‰å…¨å’Œç›£æ§
   - é›†æˆåˆ°ç¾æœ‰å·¥ä½œæµ</p>

<p>3. <strong>é•·æœŸï¼ˆ12å€‹æœˆ+ï¼‰ï¼šç”Ÿæ…‹å»ºè¨­</strong>
   - å»ºç«‹è¡Œæ¥­è¯ç›Ÿ
   - åˆ¶å®šæ¨™æº–å’Œè¦ç¯„
   - æ¢ç´¢æ–°æ‡‰ç”¨å ´æ™¯</p>

<p>---</p>

<h2>åƒè€ƒè³‡æ–™</h2>

<h3>æŠ€è¡“æ–‡æª”</h3>
- [Flower Documentation](https://flower.dev/)
- [PySyft Documentation](https://openmined.github.io/PySyft/)
- [TensorFlow Federated](https://www.tensorflow.org/federated)

<h3>è«–æ–‡</h3>
- McMahan et al. (2017). "Communication-Efficient Learning of Deep Networks from Decentralized Data"
- Bonawitz et al. (2017). "Practical Secure Aggregation for Privacy-Preserving Machine Learning"
- Dwork et al. (2014). "The Algorithmic Foundations of Differential Privacy"

<h3>é‡‘èæ‡‰ç”¨</h3>
- Yang et al. (2019). "Federated Machine Learning: Concept and Applications"
- Secure & Private AI for Financial Services (OpenMined)

<p>---</p>

<strong>ç ”ç©¶å®Œæˆæ™‚é–“ï¼š</strong> 2026-02-20
<strong>å ±å‘Šç‰ˆæœ¬ï¼š</strong> 1.0
<strong>ä½œè€…ï¼š</strong> Charlie Analyst (Subagent)
<strong>é …ç›®ï¼š</strong> Federated Learning for Collaborative Quant Research

    </div>
</body>
</html>
